{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "11_11_2020.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "DymU8LjCBaul"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from numpy import exp\n",
        "from numpy.random import seed\n",
        "seed(1)\n",
        "from math import sqrt\n",
        "import pandas as pd\n",
        "import keras\n",
        "import scipy as sp\n",
        "from scipy import stats\n",
        "import seaborn as sns \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Dense\n",
        "from tensorflow.python.keras.layers import InputLayer\n",
        "from keras import initializers\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CtsGFMsBfgT",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "2a0a8dcb-a739-45e6-980c-20f7d71aca94"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-44598662-cf92-475b-a0ad-549bb0afa8bb\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-44598662-cf92-475b-a0ad-549bb0afa8bb\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving simulation.xlsx to simulation.xlsx\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84ragK0MK41R"
      },
      "source": [
        "df=pd.read_excel('simulation.xlsx')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXMtqfqKJrsz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52a36501-0ebc-4e9c-9c8d-5c4c5055112f"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDjML3P8J9d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "467f4685-9655-4d3b-ca65-ddcd2ec6e0e9"
      },
      "source": [
        "cd /content/gdrive/My Drive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nG6c4-dKPNB"
      },
      "source": [
        "#df = pd.read_excel('/content/gdrive/My Drive/PhD with Dr Anahita/projects/chatter/simulation.xlsx')\r\n",
        "df.columns = ['A_Mpa','B_Mpa','C','N','M','FC','H','B','FT','FN','P','T']\r\n",
        "#df.head(43)\r\n",
        "#df.describe()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7KUhapzgxaR",
        "outputId": "18f5f78b-73dd-4c09-a93b-41ac2d1b0450"
      },
      "source": [
        "# to generate 30 inputs randomly\r\n",
        "A_30_random=np.random.uniform(164.000000\t,378.633259,30)\r\n",
        "B_30_random=np.random.uniform(17.871447 ,211.000000\t, 30)\r\n",
        "c_30_random=np.random.uniform(0.001000\t, 0.041100\t\t, 30)\r\n",
        "n_30_random=np.random.uniform(0.084000\t, 0.660633\t\t, 30)\r\n",
        "m_30_random=np.random.uniform(0.823872\t\t, 1.583963\t\t, 30)\r\n",
        "h_30_random=np.random.uniform(0.130000\t, 0.170000\t\t, 30)\r\n",
        "random_data=np.hstack((A_30_random.reshape(30,1),B_30_random.reshape(30,1),c_30_random.reshape(30,1),n_30_random.reshape(30,1),m_30_random.reshape(30,1),h_30_random.reshape(30,1)))\r\n",
        "df_random_30=pd.DataFrame(random_data, columns=['A_Mpa','B_Mpa','C','N','M','H'])\r\n",
        "df_random_30_from_original=df.sample(n=30)\r\n",
        "print('mape_a:', np.mean(abs((df_random_30_from_original['A_Mpa'].to_numpy()-df_random_30['A_Mpa'].to_numpy())/df_random_30_from_original['A_Mpa'].to_numpy())))\r\n",
        "print('mape_b:', np.mean(abs((df_random_30_from_original['B_Mpa'].to_numpy()-df_random_30['B_Mpa'].to_numpy())/df_random_30_from_original['B_Mpa'].to_numpy())))\r\n",
        "print('mape_c:', np.mean(abs((df_random_30_from_original['C'].to_numpy()-df_random_30['C'].to_numpy())/df_random_30_from_original['C'].to_numpy())))\r\n",
        "print('mape_n:', np.mean(abs((df_random_30_from_original['N'].to_numpy()-df_random_30['N'].to_numpy())/df_random_30_from_original['N'].to_numpy())))\r\n",
        "print('mape_m:', np.mean(abs((df_random_30_from_original['M'].to_numpy()-df_random_30['M'].to_numpy())/df_random_30_from_original['M'].to_numpy())))\r\n",
        "print('mape_h:', np.mean(abs((df_random_30_from_original['H'].to_numpy()-df_random_30['H'].to_numpy())/df_random_30_from_original['H'].to_numpy())))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mape_a: 0.2015115618433375\n",
            "mape_b: 0.6258659209046296\n",
            "mape_c: 2.058138896394659\n",
            "mape_n: 0.4084045074793465\n",
            "mape_m: 0.162094732835962\n",
            "mape_h: 0.11825661555415912\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_JOIMtKR7wE",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "3f9dcf8e-4147-4049-9339-c4ff8767e899"
      },
      "source": [
        "#loading input variables with 1%, 5% and 15% deviation\r\n",
        "#df_01_05_15_results = pd.read_excel('/content/gdrive/My Drive/PhD with Dr Anahita/projects/chatter/df_01_05_15_results.xlsx')\r\n",
        "#df_01_05_15_results.columns = ['A_Mpa','B_Mpa','C','N','M','H','FT','FN','P','T']\r\n",
        "#df_01_05_15_results.head(50)\r\n",
        "#df_01_05_15_results_inputs=df_01_05_15_results[['A_Mpa','B_Mpa','C','N','M','H']]\r\n",
        "#df_01_05_15_results_outputs=df_01_05_15_results[['FT','FN','P','T']]\r\n",
        "#below is scaled against the full dataset. df_01_05_15_results_inputs_scaled1 is scaled against this dataset. Please learn more about this. \r\n",
        "#df_01_05_15_results_inputs_scaled=scaler_x.transform(df1)\r\n",
        "#df_01_05_15_results_outputs_scaled=scaler_y.transform(df2)\r\n",
        "#df_01_05_15_results_inputs_scaled\r\n",
        "\r\n",
        "#loading input variables with 20% deviation\r\n",
        "\r\n",
        "#df_20_results = pd.read_excel('/content/gdrive/My Drive/PhD with Dr Anahita/projects/chatter/df_20_results.xlsx')\r\n",
        "#df_20_results.columns = ['A_Mpa','B_Mpa','C','N','M','H','FT','FN','P','T']\r\n",
        "#df_20_results.head(50)\r\n",
        "#df_20_results_inputs=df_20_results[['A_Mpa','B_Mpa','C','N','M','H']]\r\n",
        "#df_20_results_outputs=df_20_results[['FT','FN','P','T']]\r\n",
        "#below is scaled against the full dataset. df_20_results_inputs_scaled1 is scaled against this dataset. Please learn more about this. \r\n",
        "#df_20_results_inputs_scaled=scaler_x.transform(df_20_results_inputs)\r\n",
        "#df_20_results_outputs_scaled=scaler_y.transform(df_20_results_outputs)\r\n",
        "\r\n",
        "#loading input variables with 10, 25% deviation\r\n",
        "#from google.colab import files\r\n",
        "#uploaded = files.upload()\r\n",
        "\r\n",
        "#df_10_25_results=pd.read_excel('df_10_25_results.xlsx')\r\n",
        "\r\n",
        "#loading with 0% deviation random 30 variables. \r\n",
        "from google.colab import files\r\n",
        "uploaded = files.upload()\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-bbd1983b-99dd-4497-80cf-28bc4c28f0d0\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-bbd1983b-99dd-4497-80cf-28bc4c28f0d0\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving df_random_30_results.xlsx to df_random_30_results.xlsx\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYFHNLT6alYn",
        "outputId": "5f6af98e-36c5-4ab3-9e5c-bba010a3f9d3"
      },
      "source": [
        "df_0_30_random_results=pd.read_excel('df_random_30_results.xlsx')\r\n",
        "df_0_30_random_results.head(30)\r\n",
        "df_0_30_random_results.columns = ['A_Mpa','B_Mpa','C','N','M','H','FT','FN','P','T']\r\n",
        "df_0_30_random_results.head(50)\r\n",
        "df_0_30_random_results_inputs=df_0_30_random_results[['A_Mpa','B_Mpa','C','N','M','H']]\r\n",
        "df_0_30_random_results_outputs=df_0_30_random_results[['FT','FN','P','T']]\r\n",
        "#below is scaled against the full dataset. df_20_results_inputs_scaled1 is scaled against this dataset. Please learn more about this. \r\n",
        "df_0_30_random_results_inputs_scaled=scaler_x.transform(df_0_30_random_results_inputs)\r\n",
        "df_0_30_random_results_outputs_scaled=scaler_y.transform(df_0_30_random_results_outputs)\r\n",
        "df_0_30_random_results_outputs\r\n",
        "df_30=df.sample(n=30)\r\n",
        "print('Ft',np.mean(abs((df_30['FT'].to_numpy()-df_0_30_random_results['FT'].to_numpy())/df_30['FT'].to_numpy()*100)))\r\n",
        "print('Fn',np.mean(abs((df_30['FN'].to_numpy()-df_0_30_random_results['FN'].to_numpy())/df_30['FN'].to_numpy()*100)))\r\n",
        "print('P',np.mean(abs((df_30['P'].to_numpy()-df_0_30_random_results['P'].to_numpy())/df_30['P'].to_numpy()*100)))\r\n",
        "print('T',np.mean(abs((df_30['T'].to_numpy()-df_0_30_random_results['T'].to_numpy())/df_30['T'].to_numpy()*100)))\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ft 19.642353649756906\n",
            "Fn 21.73116673871331\n",
            "P 19.642395225495626\n",
            "T 16.364430433670183\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aIenZILcdqPi",
        "outputId": "e90ed761-d4bd-4ea6-be03-0d4da75d4e1c"
      },
      "source": [
        "#prediction for 0 percent deviation 30 random samples\r\n",
        "ynew1_0_30_random= model.predict(df_0_30_random_results_inputs_scaled)\r\n",
        "ynew0_30_random=scaler_y.inverse_transform(ynew1_0_30_random)\r\n",
        "ynew0_30_random\r\n",
        "df_0_30_random_predicted=pd.DataFrame(data=ynew0_30_random, columns=['Ft','Fn','P','T'])\r\n",
        "print('Ft:',np.mean(abs((df_0_30_random_predicted['Ft']-df_0_30_random_results_outputs['FT'])/df_0_30_random_results_outputs['FT']*100)))\r\n",
        "print('Fn:', np.mean(abs((df_0_30_random_predicted['Fn']-df_0_30_random_results_outputs['FN'])/df_0_30_random_results_outputs['FN']*100)))\r\n",
        "print('P:',np.mean(abs((df_0_30_random_predicted['P']-df_0_30_random_results_outputs['P'])/df_0_30_random_results_outputs['P']*100)))\r\n",
        "print('T:', np.mean(abs((df_0_30_random_predicted['T']-df_0_30_random_results_outputs['T'])/df_0_30_random_results_outputs['T']*100)))\r\n",
        "\r\n",
        "\r\n",
        "#print(r2_score(df_0_30_random_predicted['Ft'], df_0_30_random_results_outputs['FT']))\r\n",
        "#print(r2_score(df_0_30_random_predicted['Fn'], df_0_30_random_results_outputs['FN']))\r\n",
        "#print(r2_score(df_0_30_random_predicted['P'], df_0_30_random_results_outputs['P']))\r\n",
        "#print(r2_score(df_0_30_random_predicted['T'], df_0_30_random_results_outputs['T']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ft: 7.682801221322197\n",
            "Fn: 4.729156943008537\n",
            "P: 7.869555461476418\n",
            "T: 5.677398976801722\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glgg01GDabUe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrCCYRbDuUqw"
      },
      "source": [
        "df_10_25_results.columns = ['fgfgfg','A_Mpa','B_Mpa','C','N','M','H','FT','FN','P','T']\r\n",
        "df_10_25_results_inputs=df_10_25_results[['A_Mpa','B_Mpa','C','N','M','H']]\r\n",
        "df_10_25_results_outputs=df_10_25_results[['FT','FN','P','T']]\r\n",
        "#below is scaled against the full dataset. df_10_25_results_inputs_scaled1 is scaled against this dataset. Please learn more about this. \r\n",
        "df_10_25_results_inputs_scaled=scaler_x.transform(df_10_25_results_inputs)\r\n",
        "df_10_25_results_outputs_scaled=scaler_y.transform(df_10_25_results_outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "id": "aT_e8UcmUa-Y",
        "outputId": "06a8ce76-b8cf-4550-a078-8dc98d3577b7"
      },
      "source": [
        "df_01_05_15_results_inputs_scaled1=scaler_x.transform(df_01_05_15_results_inputs)\r\n",
        "df_01_05_15_results_outputs_scaled1=scaler_y.transform(df_01_05_15_results_outputs)\r\n",
        "#df_01_05_15_results_outputs_scaled1\r\n",
        "df_01_05_15_results_outputs_scaled1\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-126-356468e75297>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_01_05_15_results_inputs_scaled1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscaler_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_01_05_15_results_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_01_05_15_results_outputs_scaled1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscaler_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_01_05_15_results_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#df_01_05_15_results_outputs_scaled1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf_01_05_15_results_outputs_scaled1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df_01_05_15_results_inputs' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xgwxgzmJrwC"
      },
      "source": [
        "gfggfgf=np.array([125.433,\t83.982,\t1003.47,\t322.145,\r\n",
        "97.9602,\t73.3427,\t783.682,\t273.915,\r\n",
        "125.818,\t78.4145,\t1006.54,\t314.992,\r\n",
        "119.009,\t93.6906,\t952.069,\t327.104,\r\n",
        "106.134,\t72.8844,\t849.071,\t281.632,\r\n",
        "119.261,\t73.2355,\t954.088,\t299.698,\r\n",
        "131.48,\t81.9317,\t1051.84,\t330.808,\r\n",
        "117.85,\t83.5403,\t942.802,\t318.705,\r\n",
        "125.914,\t84.1501\t,1007.31,\t330.258,\r\n",
        "128.261,\t88.2943\t,1026.09,\t339.054])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYtDbhVuBf16"
      },
      "source": [
        "dfdfdf=np.array([124.658,\t83.4797,\t997.259\t,323.786,\r\n",
        "97.9558,\t73.2994\t,783.647,\t271.636,\r\n",
        "125.711,\t77.6578,\t1005.69,\t314.79,\r\n",
        "118.92,\t93.0486,\t951.357,\t328.323,\r\n",
        "106.014,\t72.5278,\t848.111\t,281.352,\r\n",
        "119.39,\t74.4082,\t955.124,\t300.087,\r\n",
        "131.889,\t82.1395,\t1055.11,\t331.746,\r\n",
        "118.358,\t84.4954,\t946.867,\t318.491,\r\n",
        "126.959,\t85.735,\t1015.67,\t331.017,\r\n",
        "127.884,\t86.9111,\t1023.07\t,336.94])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVbGWBRNG3Ns",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0ed59c0-3111-463b-8480-6fa43ae36599"
      },
      "source": [
        "np.mean(abs(gfggfgf-dfdfdf)/gfggfgf*100)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.45490650455378223"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "id": "fiFcaPnNvLqg",
        "outputId": "d8773519-d1e1-4124-8659-f0f116a179a0"
      },
      "source": [
        "def mean_absolute_percentage_error(y_true, y_pred):\r\n",
        "    y_true, y_pred = np.array(y_true), np.array(y_pred)\r\n",
        "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\r\n",
        "\r\n",
        "\r\n",
        "y_true = gfggfgf\r\n",
        "y_pred = dfdfdf\r\n",
        "\r\n",
        "print(mean_absolute_percentage_error(y_true, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-e75e5f5bc2d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgfggfgf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdfdfdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'gfggfgf' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alFmZ38N9kWo"
      },
      "source": [
        "df_input=df[['A_Mpa','B_Mpa','C','N','M','H']]\n",
        "df_output=df[['FT','FN','P','T']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTcwMhE51NYQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DVmKztlwzu-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wHdHYyiw0Jy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3bho-XisVsJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPhfauRc98eM"
      },
      "source": [
        "<center> <h3> Neural Network to predict Ft (N)\t<center> \t\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61oYIp16BgLa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c989d41-85e5-4a87-c7ad-918d976adccb"
      },
      "source": [
        "df1=df[['A_Mpa','B_Mpa','C','N','M','H']]\n",
        "df2=df[['FT','FN','P','T']]\n",
        "#df2=np.reshape(df2, (-1,4))\n",
        "scaler_x = MinMaxScaler()\n",
        "scaler_y = MinMaxScaler()\n",
        "print(scaler_x.fit(df1))\n",
        "xscale1=scaler_x.transform(df1)\n",
        "print(scaler_y.fit(df2))\n",
        "yscale1=scaler_y.transform(df2)\n",
        "\n",
        "df_test_for=df1.iloc[[1,21,41,61,81,101,141,201,251,301], ]\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MinMaxScaler(copy=True, feature_range=(0, 1))\n",
            "MinMaxScaler(copy=True, feature_range=(0, 1))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2U2R87puoOqb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CYUuHZjBggi"
      },
      "source": [
        "X_train1, X_test1, y_train1, y_test1 = train_test_split(xscale1, yscale1, test_size=.3, random_state=45)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3015aLKpPAN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1zdI7b3Bg-i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62d2b3c8-3c7a-471f-db51-436a2d6aab09"
      },
      "source": [
        "model = Sequential()\n",
        "#model.add(Dense(6, input_dim=6, kernel_initializer=keras.initializers.glorot_uniform(seed=66), activation='relu'))\n",
        "model.add(Dense(20, input_dim=6, kernel_initializer=keras.initializers.glorot_uniform(seed=66), activation='relu'))\n",
        "model.add(Dense(4,kernel_initializer=keras.initializers.glorot_uniform(seed=66), activation='linear'))\n",
        "model.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 20)                140       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 4)                 84        \n",
            "=================================================================\n",
            "Total params: 224\n",
            "Trainable params: 224\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qe8m2a07Pw7y"
      },
      "source": [
        "def sigmoid(x):\r\n",
        "    return 1 / (1 + exp(-x))\r\n",
        "  \r\n",
        "def inv_sigmoid(y):\r\n",
        "    return np.log(y/(1-y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYO9xSQsW_sc"
      },
      "source": [
        "#model.layers[0].get_weights()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJNnFjfeanHi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1142e88-476f-4eb7-e4af-ff9e2af34f98"
      },
      "source": [
        "#i=1,21,41,61,81,101,141,201,251,301, 311, 321, 331, 341...............\n",
        "i=81 #this is the index for the simulation input you want to initualize with\n",
        "#model.layers[2].get_weights()\n",
        "perc_dev=.25\n",
        "const_init=initializers.constant(inv_sigmoid(xscale1[i,:]+np.random.choice([-1,1],size=xscale1[i,:].shape)*perc_dev*xscale1[i,:]))\n",
        "model2 = Sequential()\n",
        "#model2.add(Dense(6, input_dim=1, trainable=True,kernel_initializer=initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None), use_bias=False,  activation='sigmoid'))\n",
        "model2.add(Dense(6, input_dim=1, trainable=True,kernel_initializer=const_init, use_bias=False,  activation='sigmoid'))\n",
        "model2.add(Dense(20, trainable=False, kernel_initializer=keras.initializers.glorot_uniform(seed=66), activation='relu'))\n",
        "model2.layers[1].set_weights(model.layers[0].get_weights())\n",
        "model2.add(Dense(4,  trainable=False, kernel_initializer=keras.initializers.glorot_uniform(seed=66), activation='linear'))\n",
        "model2.layers[2].set_weights(model.layers[1].get_weights())\n",
        "model2.summary()\n",
        "model2.compile(loss='mae', optimizer='adam', metrics=['mse','mae'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_23\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_68 (Dense)             (None, 6)                 6         \n",
            "_________________________________________________________________\n",
            "dense_69 (Dense)             (None, 20)                140       \n",
            "_________________________________________________________________\n",
            "dense_70 (Dense)             (None, 4)                 84        \n",
            "=================================================================\n",
            "Total params: 230\n",
            "Trainable params: 6\n",
            "Non-trainable params: 224\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtaBgWH_WahU"
      },
      "source": [
        "#model2.layers[1].get_weights() \r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXCEbelLW65e"
      },
      "source": [
        "#model.layers[0].get_weights()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLoU_vIcY-lP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLE864hBc7yf"
      },
      "source": [
        "#yscale1[1,:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PijvpfMh1cJo"
      },
      "source": [
        "#>>> history = model2.fit(np.array(1).reshape(1,1), yscale1[i,:].reshape(1,4),epochs=1000,verbose=0)\n",
        ">>> history = model2.fit(np.array(1).reshape(1,1), model.predict(xscale1[i,:].reshape(1,6)),epochs=2000,verbose=0) #train model 2 to match forward model prediction (not ground truth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7UG_0Eqzmh_"
      },
      "source": [
        " #print(history.history.keys())\n",
        "# \"Loss\"\n",
        "#plt.plot(history.history['loss'])\n",
        "#plt.plot(history.history['val_loss'])\n",
        "#plt.title('model loss')\n",
        "#plt.ylabel('loss')\n",
        "#plt.xlabel('epoch')\n",
        "#plt.legend(['train', 'validation'], loc='upper left')\n",
        "#plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iioX0D-Llk0"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVv8BSCrL7lN"
      },
      "source": [
        "#sigmoid(np.array([1,2]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZrLx_hg1mtV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c35931d4-20be-4be2-f90f-da87a6ce054a"
      },
      "source": [
        "a=np.array(model2.layers[0].get_weights()).reshape(6,1)\n",
        "#first row- [0.55415051, 0.47234515, 0.17725006, 0.53157168, 0.65380886,0.]\n",
        "ab= np.hstack((xscale1[i,:].reshape(6,1),sigmoid(a) ))\n",
        "df2222 = pd.DataFrame(data=ab, columns=[\" input variables\", \"adjusted weights as predicted input variables\"])\n",
        "df2222\n",
        "a.shape\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "byFLmz1tYblL",
        "outputId": "16225129-3177-438b-8a17-edebca953cbe"
      },
      "source": [
        "np.set_printoptions(suppress=True) #prevent numpy exponential \r\n",
        "scaler_x.inverse_transform(sigmoid(a).reshape(1,6))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[314.7952    , 115.437164  ,   0.0083153 ,   0.3989073 ,\n",
              "          1.3272016 ,   0.13875799]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "s2b7XsKPND1s",
        "outputId": "b106f879-436b-45a0-84a3-029c60c2baf6"
      },
      "source": [
        "#another backward model for another test for 20% deviation (result in array) \r\n",
        "comm='''twenty_one=np.array([[281.6041    , 108.6382    ,   0.00882467,   0.38360786,\r\n",
        "          1.3048565 ,   0.14083591]])\r\n",
        "twenty_two=np.array([[268.43646   ,  19.318731  ,   0.0190874 ,   0.30476817,\r\n",
        "          1.3104327 ,   0.1399151 ]])\r\n",
        "twenty_three=np.array([[271.65396   , 102.31428   ,   0.01015358,   0.51461035,\r\n",
        "          1.2732446 ,   0.13948542]])\r\n",
        "twenty_four=np.array([[269.73743   ,  85.97921   ,   0.02781634,   0.18680292,\r\n",
        "          1.2577845 ,   0.14085633]])\r\n",
        "twenty_five=np.array([[258.68127   ,  37.40505   ,   0.01519357,   0.46117452,\r\n",
        "          1.3979186 ,   0.1431862 ]])\r\n",
        "twenty_six=np.array([[208.76402   , 129.81871   ,   0.01427257,   0.3468534 ,\r\n",
        "          1.2661259 ,   0.13900042]])\r\n",
        "twenty_seven=np.array([[254.51093   ,  82.97607   ,   0.02717591,   0.5782928 ,\r\n",
        "          1.3445021 ,   0.13838652]])\r\n",
        "twenty_eight=np.array([[283.27496   , 125.287384  ,   0.00162938,   0.1690536 ,\r\n",
        "          1.419888  ,   0.13990492]])\r\n",
        "twenty_nine=np.array([[300.10574   , 112.34014   ,   0.00727413,   0.39801475,\r\n",
        "          1.2898488 ,   0.14005387]])\r\n",
        "twenty_ten=np.array([[296.57394   , 117.08757   ,   0.00773742,   0.29586607,\r\n",
        "          1.4025941 ,   0.14083864]])\r\n",
        "\r\n",
        "numpy_data = np.vstack((twenty_one,twenty_two,twenty_three,twenty_four,twenty_five,twenty_six,twenty_seven,twenty_eight,twenty_nine,twenty_ten))\r\n",
        "df_20_results_another = pd.DataFrame(data=numpy_data, columns=[\"A\", \"B\",\"c\",\"n\",\"m\",\"h\"])\r\n",
        "df_20_results_another\r\n",
        "'''\r\n",
        "twenty_five_one=np.array([[292.366     , 101.12462   ,   0.00962326,   0.4586523 ,\r\n",
        "          1.258683  ,   0.1402402 ]])\r\n",
        "twenty_five_two=np.array([[241.77226   ,  19.301817  ,   0.0233189 ,   0.19853012,\r\n",
        "          1.4790719 ,   0.13953044]])\r\n",
        "twenty_five_three=np.array([[276.54034   , 101.0437    ,   0.01004984,   0.52599925,\r\n",
        "          1.264487  ,   0.13919753]])\r\n",
        "twenty_five_four=np.array([[295.97525   ,  95.65604   ,   0.02105672,   0.25642592,\r\n",
        "          1.1230587 ,   0.14104378]])\r\n",
        "twenty_five_five=np.array([[273.08807   ,  30.06069   ,   0.01385654,   0.55359787,\r\n",
        "          1.3625653 ,   0.14136353]])\r\n",
        "twenty_five_six=np.array([[196.12315   , 133.43138   ,   0.01580877,   0.30251217,\r\n",
        "          1.2733579 ,   0.13949591]])\r\n",
        "twenty_five_seven=np.array([[280.40073   ,  72.55864   ,   0.02107922,   0.6179071 ,\r\n",
        "          1.3645694 ,   0.14050968]])\r\n",
        "twenty_five_eight=np.array([[304.961     , 133.79138   ,   0.00154549,   0.28121603,\r\n",
        "          1.1407007 ,   0.14100058]])\r\n",
        "twenty_five_nine=np.array([[296.94388   , 105.21835   ,   0.00812246,   0.39579213,\r\n",
        "          1.381466  ,   0.13805029]])\r\n",
        "twenty_five_ten=np.array([[309.34875   , 104.84549   ,   0.00830624,   0.39018068,\r\n",
        "          1.3848567 ,   0.13833283]])\r\n",
        "\r\n",
        "numpy_data = np.vstack((twenty_five_one,twenty_five_two,twenty_five_three,twenty_five_four,twenty_five_five,twenty_five_six,twenty_five_seven,twenty_five_eight,twenty_five_nine,twenty_five_ten))\r\n",
        "df_25_results_another1 = pd.DataFrame(data=numpy_data, columns=[\"A\", \"B\",\"c\",\"n\",\"m\",\"h\"])\r\n",
        "df_25_results_another1\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>A</th>\n",
              "      <th>B</th>\n",
              "      <th>c</th>\n",
              "      <th>n</th>\n",
              "      <th>m</th>\n",
              "      <th>h</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>292.36600</td>\n",
              "      <td>101.124620</td>\n",
              "      <td>0.009623</td>\n",
              "      <td>0.458652</td>\n",
              "      <td>1.258683</td>\n",
              "      <td>0.140240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>241.77226</td>\n",
              "      <td>19.301817</td>\n",
              "      <td>0.023319</td>\n",
              "      <td>0.198530</td>\n",
              "      <td>1.479072</td>\n",
              "      <td>0.139530</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>276.54034</td>\n",
              "      <td>101.043700</td>\n",
              "      <td>0.010050</td>\n",
              "      <td>0.525999</td>\n",
              "      <td>1.264487</td>\n",
              "      <td>0.139198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>295.97525</td>\n",
              "      <td>95.656040</td>\n",
              "      <td>0.021057</td>\n",
              "      <td>0.256426</td>\n",
              "      <td>1.123059</td>\n",
              "      <td>0.141044</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>273.08807</td>\n",
              "      <td>30.060690</td>\n",
              "      <td>0.013857</td>\n",
              "      <td>0.553598</td>\n",
              "      <td>1.362565</td>\n",
              "      <td>0.141364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>196.12315</td>\n",
              "      <td>133.431380</td>\n",
              "      <td>0.015809</td>\n",
              "      <td>0.302512</td>\n",
              "      <td>1.273358</td>\n",
              "      <td>0.139496</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>280.40073</td>\n",
              "      <td>72.558640</td>\n",
              "      <td>0.021079</td>\n",
              "      <td>0.617907</td>\n",
              "      <td>1.364569</td>\n",
              "      <td>0.140510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>304.96100</td>\n",
              "      <td>133.791380</td>\n",
              "      <td>0.001545</td>\n",
              "      <td>0.281216</td>\n",
              "      <td>1.140701</td>\n",
              "      <td>0.141001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>296.94388</td>\n",
              "      <td>105.218350</td>\n",
              "      <td>0.008122</td>\n",
              "      <td>0.395792</td>\n",
              "      <td>1.381466</td>\n",
              "      <td>0.138050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>309.34875</td>\n",
              "      <td>104.845490</td>\n",
              "      <td>0.008306</td>\n",
              "      <td>0.390181</td>\n",
              "      <td>1.384857</td>\n",
              "      <td>0.138333</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           A           B         c         n         m         h\n",
              "0  292.36600  101.124620  0.009623  0.458652  1.258683  0.140240\n",
              "1  241.77226   19.301817  0.023319  0.198530  1.479072  0.139530\n",
              "2  276.54034  101.043700  0.010050  0.525999  1.264487  0.139198\n",
              "3  295.97525   95.656040  0.021057  0.256426  1.123059  0.141044\n",
              "4  273.08807   30.060690  0.013857  0.553598  1.362565  0.141364\n",
              "5  196.12315  133.431380  0.015809  0.302512  1.273358  0.139496\n",
              "6  280.40073   72.558640  0.021079  0.617907  1.364569  0.140510\n",
              "7  304.96100  133.791380  0.001545  0.281216  1.140701  0.141001\n",
              "8  296.94388  105.218350  0.008122  0.395792  1.381466  0.138050\n",
              "9  309.34875  104.845490  0.008306  0.390181  1.384857  0.138333"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 421
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLg9F2P_YBKK",
        "outputId": "2f59d1ca-18fe-4357-9256-549f872ed21d"
      },
      "source": [
        "print(np.mean(abs(df_test_for['A_Mpa'].to_numpy()-df_25_results_another1['A'].to_numpy())/df_test_for['A_Mpa'].to_numpy()*100))\r\n",
        "print(np.mean(abs(df_test_for['B_Mpa'].to_numpy()-df_25_results_another1['B'].to_numpy())/df_test_for['B_Mpa'].to_numpy()*100))\r\n",
        "print(np.mean(abs(df_test_for['C'].to_numpy()-df_25_results_another1['c'].to_numpy())/df_test_for['C'].to_numpy()*100))\r\n",
        "print(np.mean(abs(df_test_for['N'].to_numpy()-df_25_results_another1['n'].to_numpy())/df_test_for['N'].to_numpy()*100))\r\n",
        "print(np.mean(abs(df_test_for['M'].to_numpy()-df_25_results_another1['m'].to_numpy())/df_test_for['M'].to_numpy()*100))\r\n",
        "print(np.mean(abs(df_test_for['H'].to_numpy()-df_25_results_another1['h'].to_numpy())/df_test_for['H'].to_numpy()*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5.572359836205925\n",
            "8.923037025128796\n",
            "16.103360348083473\n",
            "18.433109817004322\n",
            "6.642739924327853\n",
            "0.682197857142856\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Bag2FlovTJN",
        "outputId": "53263e1f-4ae4-47a6-d4d5-a9b0cabe4345"
      },
      "source": [
        "# to compare the average deviation between 20% and 25%\r\n",
        "tt_1= np.array([7.6278914480518605,\r\n",
        "14.608855433052458,\r\n",
        "17.49142576397976,\r\n",
        "14.715788552367636,\r\n",
        "7.534329415883526,\r\n",
        "1.428571428571426]).T\r\n",
        "tt_2=np.array([3.1008346321168636,\r\n",
        "10.703358743989899,\r\n",
        "25.879388103185086,\r\n",
        "8.430358088567933,\r\n",
        "5.84677681127077,\r\n",
        "0.6384528571428603])\r\n",
        "tt_3=np.array([2.6157894558616284,\r\n",
        "7.821606934008754,\r\n",
        "11.141138277963611,\r\n",
        "15.096708758170081,\r\n",
        "4.821740598555332,\r\n",
        "0.5975542857142855])\r\n",
        "tf_1=np.array([3.0321195637043727,\r\n",
        "12.430847932931332,\r\n",
        "15.7714127064291,\r\n",
        "8.559152862760104,\r\n",
        "8.69663907927314,\r\n",
        "0.822544285714286\r\n",
        "])\r\n",
        "tf_2=np.array([2.9853460567913763,\r\n",
        "13.717011329749273,\r\n",
        "24.025609139511694,\r\n",
        "13.016121372134066,\r\n",
        "6.6626751259771,\r\n",
        "0.6808764285714233])\r\n",
        "tf_3=np.array([5.572359836205925,\r\n",
        "8.923037025128796,\r\n",
        "16.103360348083473,\r\n",
        "18.433109817004322,\r\n",
        "6.642739924327853,\r\n",
        "0.682197857142856])\r\n",
        "np.mean(tt_3-tf_3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-2.3770444162699222"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "id": "HYQny3dMRELZ",
        "outputId": "b5c3ed64-1da2-4b98-b0e0-c46537bfdcb8"
      },
      "source": [
        "np.mean(abs(df_20_results_another.iloc[0:10, 0:1].to_numpy()-df_20_predicted.iloc[0:10, 3:4].to_numpy())/df_20_results_another.iloc[0:10, 0:1].to_numpy().to_numpy()*100)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-88-c61e54ff3572>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_20_results_another\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdf_20_predicted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mdf_20_results_another\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'to_numpy'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "S-osuFLiQE0U",
        "outputId": "6d0fe586-8333-44c3-f998-c1e51739ce86"
      },
      "source": [
        "from google.colab import files\r\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d8415f77-8a2b-4870-a984-c2175fd4dc01\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d8415f77-8a2b-4870-a984-c2175fd4dc01\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving df_20_predicted (3).xlsx to df_20_predicted (3).xlsx\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zLPPNZIQuQA"
      },
      "source": [
        "#df_01_05_15_results = pd.read_excel('/content/gdrive/My Drive/PhD with Dr Anahita/projects/chatter/df_01_05_15_results.xlsx')\r\n",
        "#df_01_05_15_results.columns = ['A_Mpa','B_Mpa','C','N','M','H','FT','FN','P','T']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C87Bh4wBN26M"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYsYxMIsTfmx"
      },
      "source": [
        "#i=1,21,41,61,81,101,141,201,251,301, 311, 321, 331, 341...............\r\n",
        "# 1, 5 and 15 percent devition of the input variables sent to Tim for FEA simulation\r\n",
        "comm='''\r\n",
        "\r\n",
        "one_1=np.array([[283.3223    , 109.356415  ,   0.00809793,   0.39269063,\r\n",
        "          1.3137951 ,   0.14004934]])\r\n",
        "one_21=np.array([[263.1898    ,  19.225557  ,   0.01945137,   0.27738994,\r\n",
        "          1.3539087 ,   0.13991545]])\r\n",
        "one_41=np.array([[251.66873   , 124.091354  ,   0.01174404,   0.43666855,\r\n",
        "          1.1915141 ,   0.13999312]])\r\n",
        "one_61=np.array([[267.505     , 105.91502   ,   0.02549052,   0.16855082,\r\n",
        "          1.1760193 ,   0.13999267]])\r\n",
        "one_81=np.array([[262.9592    ,  38.63475   ,   0.01258293,   0.4841486 ,\r\n",
        "          1.4689246 ,   0.13999774]])\r\n",
        "one_101=np.array([[204.12756   , 139.59245   ,   0.01134796,   0.2766668 ,\r\n",
        "          1.3048455 ,   0.13995323]] )\r\n",
        "one_141=np.array([[250.01366   ,  80.25048   ,   0.02479883,   0.49821562,\r\n",
        "          1.4972132 ,   0.13999704]] )\r\n",
        "one_201=np.array([[293.4178    , 121.26981   ,   0.00198381,   0.23248528,\r\n",
        "          1.3360691 ,   0.13998646]])\r\n",
        "one_251=np.array([[297.4028    , 108.68388   ,   0.00808869,   0.390541  ,\r\n",
        "          1.3268439 ,   0.13989344]])\r\n",
        "one_301=np.array([[311.26373   , 108.80625   ,   0.00807434,   0.3924961 ,\r\n",
        "          1.3219234 ,   0.13990758]])\r\n",
        "five_01=np.array([[283.3345    , 108.325     ,   0.00803591,   0.39306843,\r\n",
        "          1.3281689 ,   0.13977003]])\r\n",
        "five_21=np.array([[264.20944   ,  19.308733  ,   0.01929047,   0.28281578,\r\n",
        "          1.347803  ,   0.13979812]])\r\n",
        "five_41=np.array([[250.83519   , 124.37924   ,   0.01182667,   0.43317392,\r\n",
        "          1.194751  ,   0.13999031]])\r\n",
        "five_61=np.array([[272.25394   , 103.992714  ,   0.02507074,   0.18895836,\r\n",
        "          1.1583284 ,   0.14003439]])\r\n",
        "five_81=np.array([[261.8944    ,  41.420624  ,   0.01278002,   0.4769766 ,\r\n",
        "          1.4402591 ,   0.14077759]])\r\n",
        "five_101=np.array([[204.59071   , 142.07596   ,   0.01068902,   0.27361986,\r\n",
        "          1.2845894 ,   0.1402755 ]])\r\n",
        "\r\n",
        "five_141=np.array([[249.6513    ,  85.53605   ,   0.02387673,   0.4889256 ,\r\n",
        "          1.4824378 ,   0.13997374]])\r\n",
        "five_201=np.array([[295.11044   , 122.23381   ,   0.0019192 ,   0.24218534,\r\n",
        "          1.3078712 ,   0.14014433]])\r\n",
        "five_251=np.array([[294.71896   , 108.30981   ,   0.00822712,   0.37454712,\r\n",
        "          1.3560859 ,   0.13993292]])\r\n",
        "five_301=np.array([[311.60547   , 110.63164   ,   0.00814505,   0.39392236,\r\n",
        "          1.2937896 ,   0.1403681 ]])\r\n",
        "fifteen_01=np.array([[284.63776   , 108.798454  ,   0.00799512,   0.40080252,\r\n",
        "          1.3094779 ,   0.13983975]])\r\n",
        "fifteen_21=np.array([[264.71188   ,  19.162754  ,   0.01925486,   0.28571773,\r\n",
        "          1.3455098 ,   0.13973187]])\r\n",
        "fifteen_41=np.array([[250.378     , 121.37975   ,   0.01246023,   0.43596065,\r\n",
        "          1.2065407 ,   0.13999377]] )\r\n",
        "fifteen_61=np.array([[268.1149    , 110.72613   ,   0.02450451,   0.16359605,\r\n",
        "          1.1579994 ,   0.13997991]] )\r\n",
        "fifteen_81=np.array([[261.37912   ,  38.168194  ,   0.01264235,   0.47493806,\r\n",
        "          1.4897691 ,   0.13994977]])\r\n",
        "fifteen_101=np.array([[205.72795   , 138.88431   ,   0.01123233,   0.2838154 ,\r\n",
        "          1.3004175 ,   0.1399243 ]])\r\n",
        "fifteen_141=np.array([[245.40091   ,  79.985214  ,   0.02559674,   0.48167983,\r\n",
        "          1.5210673 ,   0.13996509]])\r\n",
        "fifteen_201=np.array([[292.62573   , 119.140396  ,   0.00193745,   0.22854999,\r\n",
        "          1.3719262 ,   0.139477  ]])\r\n",
        "fifteen_251=np.array([[296.0155    , 109.19895   ,   0.00819191,   0.38194454,\r\n",
        "          1.3321775 ,   0.14009684]])\r\n",
        "fifteen_301=np.array([[314.5786    , 109.15866   ,   0.00790144,   0.4121771 ,\r\n",
        "          1.2872885 ,   0.13983354]])\r\n",
        "\r\n",
        "numpy_data = np.vstack((one_1, one_21, one_41, one_61, one_81, one_101, one_141, one_201, one_251, one_301,five_01, five_21, five_41, five_61, five_81, five_101, five_141, five_201, five_251, five_301\r\n",
        "                        ,fifteen_01, fifteen_21, fifteen_41, fifteen_61, fifteen_81, fifteen_101, fifteen_141, fifteen_201, fifteen_251, fifteen_301))\r\n",
        "df_01_05_15 = pd.DataFrame(data=numpy_data, columns=[\"A\", \"B\",\"c\",\"n\",\"m\",\"h\"])\r\n",
        "df_01_05_15\r\n",
        "from google.colab import files\r\n",
        "df_01_05_15.to_excel('df_01_05_15.xlsx')\r\n",
        "files.download('df_01_05_15.xlsx')\r\n",
        "'''\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pfxQ-JYpg2V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17131159-1c95-4be5-d3ef-bf814ee8cdc3"
      },
      "source": [
        "model2_pred=model2.predict(np.array([1]))\n",
        "model1_pred=model.predict(xscale1[i,:].reshape(1,6))\n",
        "print(model2_pred)\n",
        "print(model1_pred)\n",
        "print(yscale1[i,:])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.02707543  0.22468022 -0.18828967 -0.27068532]]\n",
            "[[ 0.02709972  0.22467601 -0.18828954 -0.27066895]]\n",
            "[0.34472242 0.3588456  0.34473044 0.43961026]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejxHgQ6G82Ci"
      },
      "source": [
        "#np.hstack((model.predict(xscale1[2,:].reshape(1,6)).reshape(4,1), yscale1[2,:].reshape(4,1)))\n",
        "#0.28577909, 0.31446942, 0.28578478, 0.4328127 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I55Vh1S2BhWR"
      },
      "source": [
        "model.compile(loss='mse', optimizer='adam', metrics=['mse','mae'])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5ss532dBhnq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9cd973a-e249-4b87-f77b-6273f0726412"
      },
      "source": [
        ">>> history = model.fit(X_train1, y_train1,epochs=250, batch_size=50, verbose=1,validation_split=0.3, callbacks=EarlyStopping(monitor='val_loss', verbose=0,patience=15))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/250\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.2716 - mse: 0.2716 - mae: 0.4366 - val_loss: 0.2018 - val_mse: 0.2018 - val_mae: 0.3657\n",
            "Epoch 2/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1842 - mse: 0.1842 - mae: 0.3453 - val_loss: 0.1396 - val_mse: 0.1396 - val_mae: 0.2895\n",
            "Epoch 3/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1267 - mse: 0.1267 - mae: 0.2740 - val_loss: 0.0958 - val_mse: 0.0958 - val_mae: 0.2375\n",
            "Epoch 4/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0873 - mse: 0.0873 - mae: 0.2298 - val_loss: 0.0659 - val_mse: 0.0659 - val_mae: 0.2039\n",
            "Epoch 5/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0609 - mse: 0.0609 - mae: 0.1960 - val_loss: 0.0456 - val_mse: 0.0456 - val_mae: 0.1707\n",
            "Epoch 6/250\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0423 - mse: 0.0423 - mae: 0.1632 - val_loss: 0.0325 - val_mse: 0.0325 - val_mae: 0.1401\n",
            "Epoch 7/250\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0293 - mse: 0.0293 - mae: 0.1327 - val_loss: 0.0251 - val_mse: 0.0251 - val_mae: 0.1205\n",
            "Epoch 8/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0237 - mse: 0.0237 - mae: 0.1156 - val_loss: 0.0213 - val_mse: 0.0213 - val_mae: 0.1093\n",
            "Epoch 9/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0209 - mse: 0.0209 - mae: 0.1073 - val_loss: 0.0193 - val_mse: 0.0193 - val_mae: 0.1024\n",
            "Epoch 10/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0183 - mse: 0.0183 - mae: 0.0986 - val_loss: 0.0177 - val_mse: 0.0177 - val_mae: 0.0972\n",
            "Epoch 11/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0165 - mse: 0.0165 - mae: 0.0914 - val_loss: 0.0165 - val_mse: 0.0165 - val_mae: 0.0930\n",
            "Epoch 12/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0158 - mse: 0.0158 - mae: 0.0905 - val_loss: 0.0156 - val_mse: 0.0156 - val_mae: 0.0895\n",
            "Epoch 13/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0142 - mse: 0.0142 - mae: 0.0848 - val_loss: 0.0149 - val_mse: 0.0149 - val_mae: 0.0866\n",
            "Epoch 14/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0149 - mse: 0.0149 - mae: 0.0853 - val_loss: 0.0142 - val_mse: 0.0142 - val_mae: 0.0842\n",
            "Epoch 15/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0129 - mse: 0.0129 - mae: 0.0793 - val_loss: 0.0137 - val_mse: 0.0137 - val_mae: 0.0822\n",
            "Epoch 16/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0133 - mse: 0.0133 - mae: 0.0797 - val_loss: 0.0133 - val_mse: 0.0133 - val_mae: 0.0804\n",
            "Epoch 17/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0127 - mse: 0.0127 - mae: 0.0788 - val_loss: 0.0129 - val_mse: 0.0129 - val_mae: 0.0787\n",
            "Epoch 18/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0121 - mse: 0.0121 - mae: 0.0777 - val_loss: 0.0125 - val_mse: 0.0125 - val_mae: 0.0773\n",
            "Epoch 19/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0137 - mse: 0.0137 - mae: 0.0811 - val_loss: 0.0122 - val_mse: 0.0122 - val_mae: 0.0761\n",
            "Epoch 20/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0111 - mse: 0.0111 - mae: 0.0726 - val_loss: 0.0119 - val_mse: 0.0119 - val_mae: 0.0750\n",
            "Epoch 21/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0121 - mse: 0.0121 - mae: 0.0763 - val_loss: 0.0116 - val_mse: 0.0116 - val_mae: 0.0740\n",
            "Epoch 22/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0124 - mse: 0.0124 - mae: 0.0752 - val_loss: 0.0113 - val_mse: 0.0113 - val_mae: 0.0731\n",
            "Epoch 23/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0113 - mse: 0.0113 - mae: 0.0726 - val_loss: 0.0111 - val_mse: 0.0111 - val_mae: 0.0724\n",
            "Epoch 24/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0096 - mse: 0.0096 - mae: 0.0682 - val_loss: 0.0109 - val_mse: 0.0109 - val_mae: 0.0715\n",
            "Epoch 25/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0117 - mse: 0.0117 - mae: 0.0731 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0708\n",
            "Epoch 26/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0109 - mse: 0.0109 - mae: 0.0717 - val_loss: 0.0105 - val_mse: 0.0105 - val_mae: 0.0699\n",
            "Epoch 27/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0104 - mse: 0.0104 - mae: 0.0693 - val_loss: 0.0103 - val_mse: 0.0103 - val_mae: 0.0693\n",
            "Epoch 28/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0094 - mse: 0.0094 - mae: 0.0670 - val_loss: 0.0101 - val_mse: 0.0101 - val_mae: 0.0685\n",
            "Epoch 29/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0098 - mse: 0.0098 - mae: 0.0681 - val_loss: 0.0099 - val_mse: 0.0099 - val_mae: 0.0679\n",
            "Epoch 30/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0093 - mse: 0.0093 - mae: 0.0670 - val_loss: 0.0098 - val_mse: 0.0098 - val_mae: 0.0672\n",
            "Epoch 31/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0113 - mse: 0.0113 - mae: 0.0739 - val_loss: 0.0096 - val_mse: 0.0096 - val_mae: 0.0667\n",
            "Epoch 32/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0101 - mse: 0.0101 - mae: 0.0691 - val_loss: 0.0095 - val_mse: 0.0095 - val_mae: 0.0664\n",
            "Epoch 33/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0091 - mse: 0.0091 - mae: 0.0656 - val_loss: 0.0094 - val_mse: 0.0094 - val_mae: 0.0656\n",
            "Epoch 34/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0097 - mse: 0.0097 - mae: 0.0679 - val_loss: 0.0092 - val_mse: 0.0092 - val_mae: 0.0652\n",
            "Epoch 35/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - mse: 0.0088 - mae: 0.0648 - val_loss: 0.0091 - val_mse: 0.0091 - val_mae: 0.0648\n",
            "Epoch 36/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0084 - mse: 0.0084 - mae: 0.0641 - val_loss: 0.0090 - val_mse: 0.0090 - val_mae: 0.0644\n",
            "Epoch 37/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0098 - mse: 0.0098 - mae: 0.0682 - val_loss: 0.0089 - val_mse: 0.0089 - val_mae: 0.0639\n",
            "Epoch 38/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0083 - mse: 0.0083 - mae: 0.0625 - val_loss: 0.0088 - val_mse: 0.0088 - val_mae: 0.0633\n",
            "Epoch 39/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0093 - mse: 0.0093 - mae: 0.0671 - val_loss: 0.0086 - val_mse: 0.0086 - val_mae: 0.0630\n",
            "Epoch 40/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0089 - mse: 0.0089 - mae: 0.0646 - val_loss: 0.0085 - val_mse: 0.0085 - val_mae: 0.0625\n",
            "Epoch 41/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0083 - mse: 0.0083 - mae: 0.0632 - val_loss: 0.0084 - val_mse: 0.0084 - val_mae: 0.0619\n",
            "Epoch 42/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0092 - mse: 0.0092 - mae: 0.0656 - val_loss: 0.0083 - val_mse: 0.0083 - val_mae: 0.0618\n",
            "Epoch 43/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0083 - mse: 0.0083 - mae: 0.0633 - val_loss: 0.0081 - val_mse: 0.0081 - val_mae: 0.0612\n",
            "Epoch 44/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - mse: 0.0089 - mae: 0.0650 - val_loss: 0.0080 - val_mse: 0.0080 - val_mae: 0.0609\n",
            "Epoch 45/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0076 - mse: 0.0076 - mae: 0.0605 - val_loss: 0.0079 - val_mse: 0.0079 - val_mae: 0.0605\n",
            "Epoch 46/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0082 - mse: 0.0082 - mae: 0.0627 - val_loss: 0.0078 - val_mse: 0.0078 - val_mae: 0.0604\n",
            "Epoch 47/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0081 - mse: 0.0081 - mae: 0.0628 - val_loss: 0.0077 - val_mse: 0.0077 - val_mae: 0.0599\n",
            "Epoch 48/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0077 - mse: 0.0077 - mae: 0.0608 - val_loss: 0.0076 - val_mse: 0.0076 - val_mae: 0.0597\n",
            "Epoch 49/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0077 - mse: 0.0077 - mae: 0.0621 - val_loss: 0.0075 - val_mse: 0.0075 - val_mae: 0.0592\n",
            "Epoch 50/250\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0076 - mse: 0.0076 - mae: 0.0610 - val_loss: 0.0074 - val_mse: 0.0074 - val_mae: 0.0592\n",
            "Epoch 51/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - mse: 0.0089 - mae: 0.0653 - val_loss: 0.0073 - val_mse: 0.0073 - val_mae: 0.0586\n",
            "Epoch 52/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0070 - mse: 0.0070 - mae: 0.0579 - val_loss: 0.0073 - val_mse: 0.0073 - val_mae: 0.0586\n",
            "Epoch 53/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0077 - mse: 0.0077 - mae: 0.0614 - val_loss: 0.0072 - val_mse: 0.0072 - val_mae: 0.0582\n",
            "Epoch 54/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0073 - mse: 0.0073 - mae: 0.0593 - val_loss: 0.0071 - val_mse: 0.0071 - val_mae: 0.0580\n",
            "Epoch 55/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0075 - mse: 0.0075 - mae: 0.0597 - val_loss: 0.0070 - val_mse: 0.0070 - val_mae: 0.0573\n",
            "Epoch 56/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0070 - mse: 0.0070 - mae: 0.0592 - val_loss: 0.0069 - val_mse: 0.0069 - val_mae: 0.0576\n",
            "Epoch 57/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0073 - mse: 0.0073 - mae: 0.0605 - val_loss: 0.0069 - val_mse: 0.0069 - val_mae: 0.0574\n",
            "Epoch 58/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0061 - mse: 0.0061 - mae: 0.0548 - val_loss: 0.0068 - val_mse: 0.0068 - val_mae: 0.0570\n",
            "Epoch 59/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0069 - mse: 0.0069 - mae: 0.0572 - val_loss: 0.0067 - val_mse: 0.0067 - val_mae: 0.0567\n",
            "Epoch 60/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0069 - mse: 0.0069 - mae: 0.0575 - val_loss: 0.0067 - val_mse: 0.0067 - val_mae: 0.0562\n",
            "Epoch 61/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0071 - mse: 0.0071 - mae: 0.0596 - val_loss: 0.0066 - val_mse: 0.0066 - val_mae: 0.0567\n",
            "Epoch 62/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0065 - mse: 0.0065 - mae: 0.0568 - val_loss: 0.0065 - val_mse: 0.0065 - val_mae: 0.0560\n",
            "Epoch 63/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0071 - mse: 0.0071 - mae: 0.0593 - val_loss: 0.0065 - val_mse: 0.0065 - val_mae: 0.0558\n",
            "Epoch 64/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0071 - mse: 0.0071 - mae: 0.0592 - val_loss: 0.0064 - val_mse: 0.0064 - val_mae: 0.0558\n",
            "Epoch 65/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0069 - mse: 0.0069 - mae: 0.0583 - val_loss: 0.0064 - val_mse: 0.0064 - val_mae: 0.0551\n",
            "Epoch 66/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0070 - mse: 0.0070 - mae: 0.0583 - val_loss: 0.0063 - val_mse: 0.0063 - val_mae: 0.0552\n",
            "Epoch 67/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0062 - mse: 0.0062 - mae: 0.0556 - val_loss: 0.0063 - val_mse: 0.0063 - val_mae: 0.0550\n",
            "Epoch 68/250\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0066 - mse: 0.0066 - mae: 0.0574 - val_loss: 0.0062 - val_mse: 0.0062 - val_mae: 0.0547\n",
            "Epoch 69/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0064 - mse: 0.0064 - mae: 0.0550 - val_loss: 0.0062 - val_mse: 0.0062 - val_mae: 0.0547\n",
            "Epoch 70/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0069 - mse: 0.0069 - mae: 0.0573 - val_loss: 0.0061 - val_mse: 0.0061 - val_mae: 0.0544\n",
            "Epoch 71/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0064 - mse: 0.0064 - mae: 0.0550 - val_loss: 0.0061 - val_mse: 0.0061 - val_mae: 0.0538\n",
            "Epoch 72/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0057 - mse: 0.0057 - mae: 0.0518 - val_loss: 0.0060 - val_mse: 0.0060 - val_mae: 0.0543\n",
            "Epoch 73/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0066 - mse: 0.0066 - mae: 0.0572 - val_loss: 0.0060 - val_mse: 0.0060 - val_mae: 0.0536\n",
            "Epoch 74/250\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0067 - mse: 0.0067 - mae: 0.0572 - val_loss: 0.0059 - val_mse: 0.0059 - val_mae: 0.0534\n",
            "Epoch 75/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0068 - mse: 0.0068 - mae: 0.0579 - val_loss: 0.0059 - val_mse: 0.0059 - val_mae: 0.0534\n",
            "Epoch 76/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0062 - mse: 0.0062 - mae: 0.0552 - val_loss: 0.0058 - val_mse: 0.0058 - val_mae: 0.0532\n",
            "Epoch 77/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0061 - mse: 0.0061 - mae: 0.0551 - val_loss: 0.0058 - val_mse: 0.0058 - val_mae: 0.0530\n",
            "Epoch 78/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0054 - mse: 0.0054 - mae: 0.0508 - val_loss: 0.0057 - val_mse: 0.0057 - val_mae: 0.0523\n",
            "Epoch 79/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0060 - mse: 0.0060 - mae: 0.0543 - val_loss: 0.0057 - val_mse: 0.0057 - val_mae: 0.0525\n",
            "Epoch 80/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0060 - mse: 0.0060 - mae: 0.0520 - val_loss: 0.0057 - val_mse: 0.0057 - val_mae: 0.0520\n",
            "Epoch 81/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0060 - mse: 0.0060 - mae: 0.0540 - val_loss: 0.0056 - val_mse: 0.0056 - val_mae: 0.0523\n",
            "Epoch 82/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0066 - mse: 0.0066 - mae: 0.0562 - val_loss: 0.0056 - val_mse: 0.0056 - val_mae: 0.0516\n",
            "Epoch 83/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0060 - mse: 0.0060 - mae: 0.0540 - val_loss: 0.0055 - val_mse: 0.0055 - val_mae: 0.0513\n",
            "Epoch 84/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0057 - mse: 0.0057 - mae: 0.0516 - val_loss: 0.0055 - val_mse: 0.0055 - val_mae: 0.0520\n",
            "Epoch 85/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0061 - mse: 0.0061 - mae: 0.0541 - val_loss: 0.0054 - val_mse: 0.0054 - val_mae: 0.0509\n",
            "Epoch 86/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0057 - mse: 0.0057 - mae: 0.0526 - val_loss: 0.0054 - val_mse: 0.0054 - val_mae: 0.0509\n",
            "Epoch 87/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0056 - mse: 0.0056 - mae: 0.0517 - val_loss: 0.0054 - val_mse: 0.0054 - val_mae: 0.0509\n",
            "Epoch 88/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0057 - mse: 0.0057 - mae: 0.0517 - val_loss: 0.0053 - val_mse: 0.0053 - val_mae: 0.0501\n",
            "Epoch 89/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0056 - mse: 0.0056 - mae: 0.0516 - val_loss: 0.0053 - val_mse: 0.0053 - val_mae: 0.0502\n",
            "Epoch 90/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0058 - mse: 0.0058 - mae: 0.0530 - val_loss: 0.0052 - val_mse: 0.0052 - val_mae: 0.0498\n",
            "Epoch 91/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0056 - mse: 0.0056 - mae: 0.0525 - val_loss: 0.0052 - val_mse: 0.0052 - val_mae: 0.0501\n",
            "Epoch 92/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0055 - mse: 0.0055 - mae: 0.0512 - val_loss: 0.0051 - val_mse: 0.0051 - val_mae: 0.0493\n",
            "Epoch 93/250\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0054 - mse: 0.0054 - mae: 0.0506 - val_loss: 0.0051 - val_mse: 0.0051 - val_mae: 0.0495\n",
            "Epoch 94/250\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0058 - mse: 0.0058 - mae: 0.0524 - val_loss: 0.0051 - val_mse: 0.0051 - val_mae: 0.0488\n",
            "Epoch 95/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0054 - mse: 0.0054 - mae: 0.0504 - val_loss: 0.0050 - val_mse: 0.0050 - val_mae: 0.0489\n",
            "Epoch 96/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0049 - mse: 0.0049 - mae: 0.0480 - val_loss: 0.0050 - val_mse: 0.0050 - val_mae: 0.0488\n",
            "Epoch 97/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0053 - mse: 0.0053 - mae: 0.0502 - val_loss: 0.0049 - val_mse: 0.0049 - val_mae: 0.0481\n",
            "Epoch 98/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0050 - mse: 0.0050 - mae: 0.0483 - val_loss: 0.0049 - val_mse: 0.0049 - val_mae: 0.0489\n",
            "Epoch 99/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0050 - mse: 0.0050 - mae: 0.0484 - val_loss: 0.0049 - val_mse: 0.0049 - val_mae: 0.0482\n",
            "Epoch 100/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0056 - mse: 0.0056 - mae: 0.0506 - val_loss: 0.0048 - val_mse: 0.0048 - val_mae: 0.0472\n",
            "Epoch 101/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0050 - mse: 0.0050 - mae: 0.0467 - val_loss: 0.0048 - val_mse: 0.0048 - val_mae: 0.0477\n",
            "Epoch 102/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0054 - mse: 0.0054 - mae: 0.0502 - val_loss: 0.0047 - val_mse: 0.0047 - val_mae: 0.0475\n",
            "Epoch 103/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0053 - mse: 0.0053 - mae: 0.0494 - val_loss: 0.0047 - val_mse: 0.0047 - val_mae: 0.0466\n",
            "Epoch 104/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0051 - mse: 0.0051 - mae: 0.0485 - val_loss: 0.0047 - val_mse: 0.0047 - val_mae: 0.0475\n",
            "Epoch 105/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0050 - mse: 0.0050 - mae: 0.0478 - val_loss: 0.0046 - val_mse: 0.0046 - val_mae: 0.0465\n",
            "Epoch 106/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0050 - mse: 0.0050 - mae: 0.0484 - val_loss: 0.0046 - val_mse: 0.0046 - val_mae: 0.0468\n",
            "Epoch 107/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0050 - mse: 0.0050 - mae: 0.0492 - val_loss: 0.0045 - val_mse: 0.0045 - val_mae: 0.0458\n",
            "Epoch 108/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0050 - mse: 0.0050 - mae: 0.0479 - val_loss: 0.0045 - val_mse: 0.0045 - val_mae: 0.0460\n",
            "Epoch 109/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0047 - mse: 0.0047 - mae: 0.0477 - val_loss: 0.0045 - val_mse: 0.0045 - val_mae: 0.0459\n",
            "Epoch 110/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0048 - mse: 0.0048 - mae: 0.0470 - val_loss: 0.0044 - val_mse: 0.0044 - val_mae: 0.0454\n",
            "Epoch 111/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0045 - mse: 0.0045 - mae: 0.0458 - val_loss: 0.0044 - val_mse: 0.0044 - val_mae: 0.0452\n",
            "Epoch 112/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0045 - mse: 0.0045 - mae: 0.0457 - val_loss: 0.0044 - val_mse: 0.0044 - val_mae: 0.0450\n",
            "Epoch 113/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0053 - mse: 0.0053 - mae: 0.0490 - val_loss: 0.0043 - val_mse: 0.0043 - val_mae: 0.0445\n",
            "Epoch 114/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0051 - mse: 0.0051 - mae: 0.0484 - val_loss: 0.0043 - val_mse: 0.0043 - val_mae: 0.0450\n",
            "Epoch 115/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0045 - mse: 0.0045 - mae: 0.0456 - val_loss: 0.0042 - val_mse: 0.0042 - val_mae: 0.0443\n",
            "Epoch 116/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0044 - mse: 0.0044 - mae: 0.0440 - val_loss: 0.0042 - val_mse: 0.0042 - val_mae: 0.0440\n",
            "Epoch 117/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0045 - mse: 0.0045 - mae: 0.0461 - val_loss: 0.0042 - val_mse: 0.0042 - val_mae: 0.0447\n",
            "Epoch 118/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0047 - mse: 0.0047 - mae: 0.0469 - val_loss: 0.0042 - val_mse: 0.0042 - val_mae: 0.0430\n",
            "Epoch 119/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0051 - mse: 0.0051 - mae: 0.0471 - val_loss: 0.0041 - val_mse: 0.0041 - val_mae: 0.0442\n",
            "Epoch 120/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0048 - mse: 0.0048 - mae: 0.0466 - val_loss: 0.0041 - val_mse: 0.0041 - val_mae: 0.0430\n",
            "Epoch 121/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0048 - mse: 0.0048 - mae: 0.0471 - val_loss: 0.0040 - val_mse: 0.0040 - val_mae: 0.0430\n",
            "Epoch 122/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0046 - mse: 0.0046 - mae: 0.0450 - val_loss: 0.0040 - val_mse: 0.0040 - val_mae: 0.0427\n",
            "Epoch 123/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0442 - val_loss: 0.0040 - val_mse: 0.0040 - val_mae: 0.0426\n",
            "Epoch 124/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0047 - mse: 0.0047 - mae: 0.0466 - val_loss: 0.0040 - val_mse: 0.0040 - val_mae: 0.0429\n",
            "Epoch 125/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0433 - val_loss: 0.0039 - val_mse: 0.0039 - val_mae: 0.0419\n",
            "Epoch 126/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0042 - mse: 0.0042 - mae: 0.0430 - val_loss: 0.0039 - val_mse: 0.0039 - val_mae: 0.0426\n",
            "Epoch 127/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0443 - val_loss: 0.0039 - val_mse: 0.0039 - val_mae: 0.0415\n",
            "Epoch 128/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0046 - mse: 0.0046 - mae: 0.0449 - val_loss: 0.0038 - val_mse: 0.0038 - val_mae: 0.0419\n",
            "Epoch 129/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0416 - val_loss: 0.0038 - val_mse: 0.0038 - val_mae: 0.0418\n",
            "Epoch 130/250\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0048 - mse: 0.0048 - mae: 0.0458 - val_loss: 0.0038 - val_mse: 0.0038 - val_mae: 0.0410\n",
            "Epoch 131/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0042 - mse: 0.0042 - mae: 0.0434 - val_loss: 0.0037 - val_mse: 0.0037 - val_mae: 0.0408\n",
            "Epoch 132/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0435 - val_loss: 0.0037 - val_mse: 0.0037 - val_mae: 0.0410\n",
            "Epoch 133/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0042 - mse: 0.0042 - mae: 0.0438 - val_loss: 0.0037 - val_mse: 0.0037 - val_mae: 0.0406\n",
            "Epoch 134/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0418 - val_loss: 0.0037 - val_mse: 0.0037 - val_mae: 0.0410\n",
            "Epoch 135/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0430 - val_loss: 0.0036 - val_mse: 0.0036 - val_mae: 0.0400\n",
            "Epoch 136/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0044 - mse: 0.0044 - mae: 0.0432 - val_loss: 0.0036 - val_mse: 0.0036 - val_mae: 0.0396\n",
            "Epoch 137/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0406 - val_loss: 0.0036 - val_mse: 0.0036 - val_mae: 0.0396\n",
            "Epoch 138/250\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0042 - mse: 0.0042 - mae: 0.0437 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0403\n",
            "Epoch 139/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0048 - mse: 0.0048 - mae: 0.0442 - val_loss: 0.0036 - val_mse: 0.0036 - val_mae: 0.0384\n",
            "Epoch 140/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0439 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0397\n",
            "Epoch 141/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0413 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0390\n",
            "Epoch 142/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0041 - mse: 0.0041 - mae: 0.0420 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0392\n",
            "Epoch 143/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0413 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0388\n",
            "Epoch 144/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0403 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0383\n",
            "Epoch 145/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0042 - mse: 0.0042 - mae: 0.0423 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0384\n",
            "Epoch 146/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0409 - val_loss: 0.0033 - val_mse: 0.0033 - val_mae: 0.0380\n",
            "Epoch 147/250\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0403 - val_loss: 0.0033 - val_mse: 0.0033 - val_mae: 0.0379\n",
            "Epoch 148/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0427 - val_loss: 0.0033 - val_mse: 0.0033 - val_mae: 0.0380\n",
            "Epoch 149/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0402 - val_loss: 0.0033 - val_mse: 0.0033 - val_mae: 0.0371\n",
            "Epoch 150/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0390 - val_loss: 0.0032 - val_mse: 0.0032 - val_mae: 0.0381\n",
            "Epoch 151/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0395 - val_loss: 0.0032 - val_mse: 0.0032 - val_mae: 0.0370\n",
            "Epoch 152/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0041 - mse: 0.0041 - mae: 0.0410 - val_loss: 0.0032 - val_mse: 0.0032 - val_mae: 0.0373\n",
            "Epoch 153/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0041 - mse: 0.0041 - mae: 0.0413 - val_loss: 0.0032 - val_mse: 0.0032 - val_mae: 0.0364\n",
            "Epoch 154/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0042 - mse: 0.0042 - mae: 0.0412 - val_loss: 0.0032 - val_mse: 0.0032 - val_mae: 0.0379\n",
            "Epoch 155/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0409 - val_loss: 0.0031 - val_mse: 0.0031 - val_mae: 0.0369\n",
            "Epoch 156/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0410 - val_loss: 0.0031 - val_mse: 0.0031 - val_mae: 0.0361\n",
            "Epoch 157/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0394 - val_loss: 0.0031 - val_mse: 0.0031 - val_mae: 0.0367\n",
            "Epoch 158/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0365 - val_loss: 0.0031 - val_mse: 0.0031 - val_mae: 0.0360\n",
            "Epoch 159/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0375 - val_loss: 0.0031 - val_mse: 0.0031 - val_mae: 0.0361\n",
            "Epoch 160/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0384 - val_loss: 0.0030 - val_mse: 0.0030 - val_mae: 0.0357\n",
            "Epoch 161/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0395 - val_loss: 0.0030 - val_mse: 0.0030 - val_mae: 0.0361\n",
            "Epoch 162/250\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0032 - mse: 0.0032 - mae: 0.0358 - val_loss: 0.0030 - val_mse: 0.0030 - val_mae: 0.0357\n",
            "Epoch 163/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0385 - val_loss: 0.0030 - val_mse: 0.0030 - val_mae: 0.0364\n",
            "Epoch 164/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0385 - val_loss: 0.0030 - val_mse: 0.0030 - val_mae: 0.0353\n",
            "Epoch 165/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0363 - val_loss: 0.0030 - val_mse: 0.0030 - val_mae: 0.0353\n",
            "Epoch 166/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0385 - val_loss: 0.0029 - val_mse: 0.0029 - val_mae: 0.0354\n",
            "Epoch 167/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0389 - val_loss: 0.0029 - val_mse: 0.0029 - val_mae: 0.0344\n",
            "Epoch 168/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0369 - val_loss: 0.0029 - val_mse: 0.0029 - val_mae: 0.0353\n",
            "Epoch 169/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0371 - val_loss: 0.0029 - val_mse: 0.0029 - val_mae: 0.0345\n",
            "Epoch 170/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0375 - val_loss: 0.0029 - val_mse: 0.0029 - val_mae: 0.0348\n",
            "Epoch 171/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0393 - val_loss: 0.0029 - val_mse: 0.0029 - val_mae: 0.0344\n",
            "Epoch 172/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0031 - mse: 0.0031 - mae: 0.0350 - val_loss: 0.0029 - val_mse: 0.0029 - val_mae: 0.0349\n",
            "Epoch 173/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0385 - val_loss: 0.0028 - val_mse: 0.0028 - val_mae: 0.0341\n",
            "Epoch 174/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0385 - val_loss: 0.0028 - val_mse: 0.0028 - val_mae: 0.0340\n",
            "Epoch 175/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0379 - val_loss: 0.0028 - val_mse: 0.0028 - val_mae: 0.0350\n",
            "Epoch 176/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0369 - val_loss: 0.0028 - val_mse: 0.0028 - val_mae: 0.0345\n",
            "Epoch 177/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0356 - val_loss: 0.0028 - val_mse: 0.0028 - val_mae: 0.0350\n",
            "Epoch 178/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0374 - val_loss: 0.0028 - val_mse: 0.0028 - val_mae: 0.0332\n",
            "Epoch 179/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0031 - mse: 0.0031 - mae: 0.0359 - val_loss: 0.0028 - val_mse: 0.0028 - val_mae: 0.0331\n",
            "Epoch 180/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0357 - val_loss: 0.0027 - val_mse: 0.0027 - val_mae: 0.0345\n",
            "Epoch 181/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0382 - val_loss: 0.0027 - val_mse: 0.0027 - val_mae: 0.0334\n",
            "Epoch 182/250\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0374 - val_loss: 0.0027 - val_mse: 0.0027 - val_mae: 0.0328\n",
            "Epoch 183/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0031 - mse: 0.0031 - mae: 0.0340 - val_loss: 0.0027 - val_mse: 0.0027 - val_mae: 0.0347\n",
            "Epoch 184/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0387 - val_loss: 0.0027 - val_mse: 0.0027 - val_mae: 0.0331\n",
            "Epoch 185/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0368 - val_loss: 0.0027 - val_mse: 0.0027 - val_mae: 0.0342\n",
            "Epoch 186/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0389 - val_loss: 0.0027 - val_mse: 0.0027 - val_mae: 0.0328\n",
            "Epoch 187/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0032 - mse: 0.0032 - mae: 0.0351 - val_loss: 0.0027 - val_mse: 0.0027 - val_mae: 0.0344\n",
            "Epoch 188/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0032 - mse: 0.0032 - mae: 0.0353 - val_loss: 0.0027 - val_mse: 0.0027 - val_mae: 0.0332\n",
            "Epoch 189/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0032 - mse: 0.0032 - mae: 0.0358 - val_loss: 0.0026 - val_mse: 0.0026 - val_mae: 0.0333\n",
            "Epoch 190/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0032 - mse: 0.0032 - mae: 0.0360 - val_loss: 0.0026 - val_mse: 0.0026 - val_mae: 0.0324\n",
            "Epoch 191/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0328 - val_loss: 0.0026 - val_mse: 0.0026 - val_mae: 0.0344\n",
            "Epoch 192/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0374 - val_loss: 0.0026 - val_mse: 0.0026 - val_mae: 0.0323\n",
            "Epoch 193/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0346 - val_loss: 0.0026 - val_mse: 0.0026 - val_mae: 0.0336\n",
            "Epoch 194/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0031 - mse: 0.0031 - mae: 0.0357 - val_loss: 0.0026 - val_mse: 0.0026 - val_mae: 0.0328\n",
            "Epoch 195/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0374 - val_loss: 0.0026 - val_mse: 0.0026 - val_mae: 0.0316\n",
            "Epoch 196/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0362 - val_loss: 0.0026 - val_mse: 0.0026 - val_mae: 0.0348\n",
            "Epoch 197/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0361 - val_loss: 0.0026 - val_mse: 0.0026 - val_mae: 0.0319\n",
            "Epoch 198/250\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0373 - val_loss: 0.0026 - val_mse: 0.0026 - val_mae: 0.0320\n",
            "Epoch 199/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0373 - val_loss: 0.0026 - val_mse: 0.0026 - val_mae: 0.0317\n",
            "Epoch 200/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0031 - mse: 0.0031 - mae: 0.0345 - val_loss: 0.0025 - val_mse: 0.0025 - val_mae: 0.0324\n",
            "Epoch 201/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0367 - val_loss: 0.0025 - val_mse: 0.0025 - val_mae: 0.0329\n",
            "Epoch 202/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0350 - val_loss: 0.0025 - val_mse: 0.0025 - val_mae: 0.0319\n",
            "Epoch 203/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0032 - mse: 0.0032 - mae: 0.0345 - val_loss: 0.0025 - val_mse: 0.0025 - val_mae: 0.0331\n",
            "Epoch 204/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0032 - mse: 0.0032 - mae: 0.0364 - val_loss: 0.0025 - val_mse: 0.0025 - val_mae: 0.0316\n",
            "Epoch 205/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0353 - val_loss: 0.0025 - val_mse: 0.0025 - val_mae: 0.0323\n",
            "Epoch 206/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0031 - mse: 0.0031 - mae: 0.0346 - val_loss: 0.0025 - val_mse: 0.0025 - val_mae: 0.0320\n",
            "Epoch 207/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0364 - val_loss: 0.0025 - val_mse: 0.0025 - val_mae: 0.0311\n",
            "Epoch 208/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0314 - val_loss: 0.0025 - val_mse: 0.0025 - val_mae: 0.0346\n",
            "Epoch 209/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0396 - val_loss: 0.0026 - val_mse: 0.0026 - val_mae: 0.0314\n",
            "Epoch 210/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0322 - val_loss: 0.0025 - val_mse: 0.0025 - val_mae: 0.0336\n",
            "Epoch 211/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0362 - val_loss: 0.0025 - val_mse: 0.0025 - val_mae: 0.0315\n",
            "Epoch 212/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0032 - mse: 0.0032 - mae: 0.0360 - val_loss: 0.0025 - val_mse: 0.0025 - val_mae: 0.0309\n",
            "Epoch 213/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0321 - val_loss: 0.0025 - val_mse: 0.0025 - val_mae: 0.0330\n",
            "Epoch 214/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0384 - val_loss: 0.0025 - val_mse: 0.0025 - val_mae: 0.0308\n",
            "Epoch 215/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0322 - val_loss: 0.0025 - val_mse: 0.0025 - val_mae: 0.0314\n",
            "Epoch 216/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0378 - val_loss: 0.0025 - val_mse: 0.0025 - val_mae: 0.0309\n",
            "Epoch 217/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0346 - val_loss: 0.0024 - val_mse: 0.0024 - val_mae: 0.0319\n",
            "Epoch 218/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0357 - val_loss: 0.0024 - val_mse: 0.0024 - val_mae: 0.0311\n",
            "Epoch 219/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0031 - mse: 0.0031 - mae: 0.0339 - val_loss: 0.0024 - val_mse: 0.0024 - val_mae: 0.0307\n",
            "Epoch 220/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0353 - val_loss: 0.0024 - val_mse: 0.0024 - val_mae: 0.0316\n",
            "Epoch 221/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0353 - val_loss: 0.0024 - val_mse: 0.0024 - val_mae: 0.0308\n",
            "Epoch 222/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0324 - val_loss: 0.0024 - val_mse: 0.0024 - val_mae: 0.0312\n",
            "Epoch 223/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0330 - val_loss: 0.0024 - val_mse: 0.0024 - val_mae: 0.0311\n",
            "Epoch 224/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0326 - val_loss: 0.0024 - val_mse: 0.0024 - val_mae: 0.0312\n",
            "Epoch 225/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0335 - val_loss: 0.0024 - val_mse: 0.0024 - val_mae: 0.0304\n",
            "Epoch 226/250\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0351 - val_loss: 0.0024 - val_mse: 0.0024 - val_mae: 0.0321\n",
            "Epoch 227/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0337 - val_loss: 0.0024 - val_mse: 0.0024 - val_mae: 0.0312\n",
            "Epoch 228/250\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0031 - mse: 0.0031 - mae: 0.0362 - val_loss: 0.0024 - val_mse: 0.0024 - val_mae: 0.0308\n",
            "Epoch 229/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0344 - val_loss: 0.0024 - val_mse: 0.0024 - val_mae: 0.0317\n",
            "Epoch 230/250\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0339 - val_loss: 0.0024 - val_mse: 0.0024 - val_mae: 0.0310\n",
            "Epoch 231/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0325 - val_loss: 0.0024 - val_mse: 0.0024 - val_mae: 0.0312\n",
            "Epoch 232/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0347 - val_loss: 0.0024 - val_mse: 0.0024 - val_mae: 0.0314\n",
            "Epoch 233/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0031 - mse: 0.0031 - mae: 0.0347 - val_loss: 0.0024 - val_mse: 0.0024 - val_mae: 0.0309\n",
            "Epoch 234/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0323 - val_loss: 0.0024 - val_mse: 0.0024 - val_mae: 0.0316\n",
            "Epoch 235/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0381 - val_loss: 0.0025 - val_mse: 0.0025 - val_mae: 0.0305\n",
            "Epoch 236/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0342 - val_loss: 0.0024 - val_mse: 0.0024 - val_mae: 0.0328\n",
            "Epoch 237/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0345 - val_loss: 0.0024 - val_mse: 0.0024 - val_mae: 0.0305\n",
            "Epoch 238/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0346 - val_loss: 0.0024 - val_mse: 0.0024 - val_mae: 0.0301\n",
            "Epoch 239/250\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0344 - val_loss: 0.0023 - val_mse: 0.0023 - val_mae: 0.0303\n",
            "Epoch 240/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0306 - val_loss: 0.0023 - val_mse: 0.0023 - val_mae: 0.0323\n",
            "Epoch 241/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0032 - mse: 0.0032 - mae: 0.0358 - val_loss: 0.0023 - val_mse: 0.0023 - val_mae: 0.0303\n",
            "Epoch 242/250\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0308 - val_loss: 0.0023 - val_mse: 0.0023 - val_mae: 0.0308\n",
            "Epoch 243/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0332 - val_loss: 0.0023 - val_mse: 0.0023 - val_mae: 0.0304\n",
            "Epoch 244/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0344 - val_loss: 0.0023 - val_mse: 0.0023 - val_mae: 0.0311\n",
            "Epoch 245/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0349 - val_loss: 0.0023 - val_mse: 0.0023 - val_mae: 0.0300\n",
            "Epoch 246/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0337 - val_loss: 0.0023 - val_mse: 0.0023 - val_mae: 0.0322\n",
            "Epoch 247/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0032 - mse: 0.0032 - mae: 0.0348 - val_loss: 0.0023 - val_mse: 0.0023 - val_mae: 0.0301\n",
            "Epoch 248/250\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0329 - val_loss: 0.0023 - val_mse: 0.0023 - val_mae: 0.0305\n",
            "Epoch 249/250\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0354 - val_loss: 0.0023 - val_mse: 0.0023 - val_mae: 0.0298\n",
            "Epoch 250/250\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0032 - mse: 0.0032 - mae: 0.0336 - val_loss: 0.0023 - val_mse: 0.0023 - val_mae: 0.0311\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsDhvDq1kB8y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "e22c6036-23c2-4170-9edf-6fd9d538d099"
      },
      "source": [
        "print(history.history.keys())\n",
        "# \"Loss\"\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['loss', 'mse', 'mae', 'val_loss', 'val_mse', 'val_mae'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de5hddX3v8fd37evckkwuhNwkkWIJCZiEMdAiqAVpwApewGDVIx4rrdUHfWr7nKiteKj2YPVYji1V8JhWPQhiEEh7Qqlo8HIQTKIQCSESQpBJIJlM7pmZff2eP9bak53JnmQSZs2ezP68nmc/e+112981G/Ynv/Vb+7fM3RERERkoqHcBIiIyOikgRESkJgWEiIjUpIAQEZGaFBAiIlKTAkJERGpSQIgMAzP7VzP73BDX3Wpml73S/YjETQEhIiI1KSBERKQmBYQ0jOjUzl+Z2XozO2Rm3zCzqWb2oJkdMLOHzay9av2rzGyDme01s0fMbG7VsoVm9stou+8C2QHv9Udm9kS07aNmdt5J1vwhM9tsZrvNbKWZTY/mm5n9g5ntNLP9ZvZrM5sfLbvSzJ6OattmZn95Un8waXgKCGk07wTeDLwGeCvwIPApYArh/w83ApjZa4C7gI9Hy1YB/2ZmaTNLA/cD3wYmAt+L9ku07UJgOfCnwCTgdmClmWVOpFAz+wPgfwDvAqYBLwB3R4svBy6JjmN8tE53tOwbwJ+6exswH/jRibyvSIUCQhrNP7r7DnffBvwUeNzdf+XufcB9wMJovaXA/3X3H7h7AfgS0AT8PnAhkAJudfeCu68A1lS9xw3A7e7+uLuX3P2bQC7a7kS8B1ju7r909xzwSeD3zGw2UADagLMBc/eN7v5StF0BOMfMxrn7Hnf/5Qm+rwiggJDGs6NqurfG69Zoejrhv9gBcPcy8CIwI1q2zY8c6fKFqukzgE9Ep5f2mtleYFa03YkYWMNBwlbCDHf/EfBPwG3ATjO7w8zGRau+E7gSeMHMfmxmv3eC7ysCKCBEBrOd8IseCM/5E37JbwNeAmZE8ypeVTX9IvB5d59Q9Wh297teYQ0thKestgG4+1fc/XzgHMJTTX8VzV/j7lcDpxGeCrvnBN9XBFBAiAzmHuAtZnapmaWATxCeJnoU+DlQBG40s5SZvQNYXLXt14E/M7MLos7kFjN7i5m1nWANdwEfMLMFUf/F3xGeEttqZq+L9p8CDgF9QDnqI3mPmY2PTo3tB8qv4O8gDUwBIVKDu28C3gv8I7CLsEP7re6ed/c88A7gemA3YX/F96u2XQt8iPAU0B5gc7TuidbwMPA3wL2ErZYzgeuixeMIg2gP4WmobuCL0bL3AVvNbD/wZ4R9GSInzHTDIBERqUUtCBERqUkBISIiNSkgRESkJgWEiIjUlKx3AcNl8uTJPnv27HqXISJySlm3bt0ud59Sa9mYCYjZs2ezdu3aepchInJKMbMXBlumU0wiIlJTrAFhZkvMbFM0XPGyGsv/IhqWeL2Z/dDMqocVKEXDJT9hZivjrFNERI4W2ykmM0sQDiT2ZqATWGNmK9396arVfgV0uHuPmX0Y+HvCX6UC9Lr7grjqExGRY4uzD2IxsNndtwCY2d3A1UB/QLj76qr1HyMc2mDYFAoFOjs76evrG87dNrRsNsvMmTNJpVL1LkVEYhZnQMwgHNWyohO44Bjrf5Dw5i0VWTNbSzgo2i3ufv+JFtDZ2UlbWxuzZ8/myIE35WS4O93d3XR2djJnzpx6lyMiMRsVVzGZ2XuBDuANVbPPcPdtZvZq4Edm9mt3f27AdjcQ3pyFV72qerTlUF9fn8JhGJkZkyZNoqurq96liMgIiLOTehvh+PkVM6N5RzCzy4BPA1dFd80CILrjF9Epqkc4fKcvqta5w9073L1jypSal/EqHIaZ/p4ijSPOgFgDnGVmc6J7+F4HHHE1UnTv3tsJw2Fn1fz2yv17zWwycBFVfRfDqVR2Xt7XR0++GMfuRUROWbEFhLsXgY8CDwEbgXvcfYOZ3WxmV0WrfZHwFo/fG3A561xgrZk9Cawm7IOIJSDcnZ0H+ujJl+LYPXv37uWf//mfT3i7K6+8kr1798ZQkYjI0MTaB+Huq4BVA+Z9pmr6skG2exQ4N87a+lnlPePZfSUg/vzP//yI+cVikWRy8D//qlWrBl0mIjISRkUndT0FUUI48STEsmXLeO6551iwYAGpVIpsNkt7ezvPPPMMv/nNb3jb297Giy++SF9fHx/72Me44YYbgMNDhxw8eJArrriC17/+9Tz66KPMmDGDBx54gKampljqFRGpaJiA+O//toGnt++vuexQrkg6GZBKnNgZt3Omj+Omt8475jq33HILTz31FE888QSPPPIIb3nLW3jqqaf6LxNdvnw5EydOpLe3l9e97nW8853vZNKkSUfs49lnn+Wuu+7i61//Ou9617u49957ee97h/UnIyIiR2mYgDiekbrx6uLFi4/4DcFXvvIV7rvvPgBefPFFnn322aMCYs6cOSxYEP6o/Pzzz2fr1q0jVK2INLKGCYhj/Uv/1537mNKW5vTx8Z+2aWlp6Z9+5JFHePjhh/n5z39Oc3Mzb3zjG2v+6juTyfRPJxIJent7Y69TRESjuQJm8bUg2traOHDgQM1l+/bto729nebmZp555hkee+yxmKoQETlxDdOCOBYjvquYJk2axEUXXcT8+fNpampi6tSp/cuWLFnC1772NebOncvv/u7vcuGFF8ZThIjISTCP65txhHV0dPjAGwZt3LiRuXPnHnfbp7fvZ3xTihntujJoKIb6dxWR0c/M1rl7R61lOsVE5RTT2AhKEZHhooAg3lNMIiKnKgUEQIyd1CIipyoFBGAYY6UvRkRkuCggiPoglA8iIkdQQNA/Xp+IiFRRQBDeBKc8SpoQra2tAGzfvp1rrrmm5jpvfOMbGXhJ70C33norPT09/a81fLiInCgFBNFVTPUuYoDp06ezYsWKk95+YECsWrWKCRMmDEdpItIgFBCEfRBxJcSyZcu47bbb+l9/9rOf5XOf+xyXXnopixYt4txzz+WBBx44arutW7cyf/58AHp7e7nuuuuYO3cub3/7248Yi+nDH/4wHR0dzJs3j5tuugkIBwDcvn07b3rTm3jTm94EhMOH79q1C4Avf/nLzJ8/n/nz53Prrbf2v9/cuXP50Ic+xLx587j88ss15pNIg2ucoTYeXAYv/7rmommF6G5yqcSJ7fP0c+GKW465ytKlS/n4xz/ORz7yEQDuueceHnroIW688UbGjRvHrl27uPDCC7nqqqsGvd/zV7/6VZqbm9m4cSPr169n0aJF/cs+//nPM3HiREqlEpdeeinr16/nxhtv5Mtf/jKrV69m8uTJR+xr3bp1/Mu//AuPP/447s4FF1zAG97wBtrb2zWsuIgcQS0IKqeY4mlCLFy4kJ07d7J9+3aefPJJ2tvbOf300/nUpz7Feeedx2WXXca2bdvYsWPHoPv4yU9+0v9Ffd5553Heeef1L7vnnntYtGgRCxcuZMOGDTz99LHvzPqzn/2Mt7/97bS0tNDa2so73vEOfvrTnwIaVlxEjtQ4LYhj/Et/R/chcsUyr5naFstbX3vttaxYsYKXX36ZpUuXcuedd9LV1cW6detIpVLMnj275jDfx/P888/zpS99iTVr1tDe3s71119/Uvup0LDiIlJNLQjiH2pj6dKl3H333axYsYJrr72Wffv2cdppp5FKpVi9ejUvvPDCMbe/5JJL+M53vgPAU089xfr16wHYv38/LS0tjB8/nh07dvDggw/2bzPYMOMXX3wx999/Pz09PRw6dIj77ruPiy++eBiPVkTGisZpQRyDmcU6WN+8efM4cOAAM2bMYNq0abznPe/hrW99K+eeey4dHR2cffbZx9z+wx/+MB/4wAeYO3cuc+fO5fzzzwfgta99LQsXLuTss89m1qxZXHTRRf3b3HDDDSxZsoTp06ezevXq/vmLFi3i+uuvZ/HixQD8yZ/8CQsXLtTpJBE5iob7Bl7c3cPBXJG508bFVd6YouG+RcYODfd9HBpqQ0TkaAoI4j/FJCJyKhrzATGUU2gGo++n1KPUWDklKSLHN6YDIpvN0t3dfdwvNTMoj1BNpzJ3p7u7m2w2W+9SRGQEjOmrmGbOnElnZyddXV3HXG9/b4EDfUWS+3VP6uPJZrPMnDmz3mWIyAgY0wGRSqWYM2fOcde79eHfcOvDz7Ll764kCDT4t4gIjPFTTEOVSoR/hkJZJ5pERCoUEEAyajUUS+qAFRGpUEAAyagFoYAQETlMAQGkE2ELIl/SKSYRkYpYA8LMlpjZJjPbbGbLaiz/CzN72szWm9kPzeyMqmXvN7Nno8f746wzFTgBZYrqgxAR6RdbQJhZArgNuAI4B3i3mZ0zYLVfAR3ufh6wAvj7aNuJwE3ABcBi4CYza4+l0IM7ue7BBfxx4oc6xSQiUiXOFsRiYLO7b3H3PHA3cHX1Cu6+2t0rN05+DKhcYP+HwA/cfbe77wF+ACyJpcpECoAURQo6xSQi0i/OgJgBvFj1ujOaN5gPApUbGgxpWzO7wczWmtna4/0YblCJNBAGRLGsFoSISMWo6KQ2s/cCHcAXT2Q7d7/D3TvcvWPKlCkn9+b9AVFSC0JEpEqcAbENmFX1emY07whmdhnwaeAqd8+dyLbDIgh/TJ62AgX1QYiI9IszINYAZ5nZHDNLA9cBK6tXMLOFwO2E4bCzatFDwOVm1h51Tl8ezRt+ZpSDFGmKFNWCEBHpF9tYTO5eNLOPEn6xJ4Dl7r7BzG4G1rr7SsJTSq3A98wM4LfufpW77zazvyUMGYCb3X13XLWWE5mok1otCBGRilgH63P3VcCqAfM+UzV92TG2XQ4sj6+6qvcKUlEntVoQIiIVo6KTuu4qAaEWhIhIPwUE4Ik0GdPvIEREqikgABIp9UGIiAyggAA86qRWH4SIyGEKCMDUghAROYoCAiCR1u8gREQGUEAAJNOkrUhBYzGJiPRTQACWSEeXuaoFISJSoYAALJnW7yBERAZQQACWDK9i0i1HRUQOU0AQtiDSakGIiBxBAQEEibCTWr+DEBE5TAEBkAiH+9bvIEREDlNAAER9ELqKSUTkMAUEQCJNynRPahGRagoIiAbrK+kqJhGRKgoIiIbaKFAslupdiYjIqKGAAEikCXDKpWK9KxERGTUUEACJNAClYr7OhYiIjB4KCDgcEAUFhIhIhQICIJECoFzM1bkQEZHRQwEB/S0IV0CIiPRTQEBVQOgUk4hIhQICIBkGRFkBISLSTwEB/S0ISgoIEZEKBQToFJOISA0KCOi/isnUghAR6aeAAJ1iEhGpQQEBkMiEz6VCfesQERlFFBDQf4qJsloQIiIVCgjoP8VkpQLuuieEiAgoIEJRQKQp6J4QIiKRWAPCzJaY2SYz22xmy2osv8TMfmlmRTO7ZsCykpk9ET1Wxlln5RRT2orkiwoIERGAZFw7NrMEcBvwZqATWGNmK9396arVfgtcD/xljV30uvuCuOo7QtSCSFFSQIiIRGILCGAxsNndtwCY2d3A1UB/QLj71mhZfb+Vk+FVTCmKOsUkIhKJ8xTTDODFqted0byhyprZWjN7zMzeVmsFM7shWmdtV1fXyVcanWJKUSRXUECIiMDo7qQ+w907gD8GbjWzMweu4O53uHuHu3dMmTLl5N9JndQiIkeJMyC2AbOqXs+M5g2Ju2+LnrcAjwALh7O4IwTqpBYRGSjOgFgDnGVmc8wsDVwHDOlqJDNrN7NMND0ZuIiqvothFwSULRmeYlJAiIgAMQaEuxeBjwIPARuBe9x9g5ndbGZXAZjZ68ysE7gWuN3MNkSbzwXWmtmTwGrglgFXPw1/vYk0KUrkiqU430ZE5JQR51VMuPsqYNWAeZ+pml5DeOpp4HaPAufGWdtR7xmkwquY1IIQEQFGdyf1iPJEmgwFBYSISEQBUZFI6XcQIiJVFBAViQxp0+8gREQqFBAVyQxZ8mpBiIhEFBARSzWpD0JEpIoCoiKVJWt5BYSISEQBEQlSTWTJ63cQIiIRBUTE0k1kUAtCRKRCARGxZJYmK5BTJ7WICDDEgDCzj5nZOAt9I7oL3OVxFzeikk1k1UktItJvqC2I/+ru+4HLgXbgfcAtsVVVD1EntQbrExEJDTUgLHq+Evi2u2+omjc2JLPqgxARqTLUgFhnZv9JGBAPmVkbMLa+SVNRJ3VBVzGJiMDQR3P9ILAA2OLuPWY2EfhAfGXVQTJDgFMu5updiYjIqDDUFsTvAZvcfa+ZvRf4a2BffGXVQbIJgHKhr86FiIiMDkMNiK8CPWb2WuATwHPAt2Krqh5S2fC52FvfOkRERomhBkTR3R24Gvgnd78NaIuvrDqIWhCmFoSICDD0PogDZvZJwstbLzazAEjFV1YdRC0IKyogRERg6C2IpUCO8PcQLxPeJvSLsVVVD8nKKSYFhIgIDDEgolC4ExhvZn8E9Ln72OqDiALCSrqKSUQEhj7UxruAXwDXAu8CHjeza+IsbMSloj4IdVKLiABD74P4NPA6d98JYGZTgIeBFXEVNuKS6oMQEak21D6IoBIOke4T2PbUUGlBlBQQIiIw9BbEf5jZQ8Bd0eulwKp4SqqTZAaARDFHuewEwdgaakpE5EQNKSDc/a/M7J3ARdGsO9z9vvjKqoPodxAZK9BXLNGcHmp2ioiMTUP+FnT3e4F7Y6ylvqLfQWTJ05NXQIiIHPNb0MwOAF5rEeDuPi6WquohakFkydOb14iuIiLHDAh3H1vDaRxL1AeRsTy9GvJbRGSMXYn0SphRSmTUghARiSggqpQT2f4+CBGRRqeAqOLJLBkK9OkUk4hIvAFhZkvMbJOZbTazZTWWX2JmvzSz4sChO8zs/Wb2bPR4f5x19ktmyZpaECIiEGNAmFkCuA24AjgHeLeZnTNgtd8C1wPfGbDtROAm4AJgMXCTmbXHVWu/VBNZCuqkFhEh3hbEYmCzu29x9zxwN+ENh/q5+1Z3Xw+UB2z7h8AP3H23u+8BfgAsibFWACyZjTqpi3G/lYjIqBdnQMwAXqx63RnNG7ZtzewGM1trZmu7urpOutCKIN1EVpe5iogAp3gntbvf4e4d7t4xZcqUV7y/INVEhoL6IEREiDcgtgGzql7PjObFve1Js1QTTabfQYiIQLwBsQY4y8zmmFkauA5YOcRtHwIuN7P2qHP68mhevFJZmkyd1CIiEGNAuHsR+CjhF/tG4B5332BmN5vZVQBm9joz6yS8U93tZrYh2nY38LeEIbMGuDmaF69UM83kdIpJRIQTGM31ZLj7KgbcN8LdP1M1vYbw9FGtbZcDy+Os7yiZNprpVQtCRIRTvJN62KVbaKKP3pwucxURUUBUS7cS4JRzh+pdiYhI3SkgqmVaw+f8wfrWISIyCiggqqXD219YXi0IEREFRLWoBREUD9S5EBGR+lNAVEuHAZEo9NS5EBGR+lNAVIsCIllQH4SIiAKiWnSKKVXqwd3rXIyISH0pIKpFLYgm+sgVB45ALiLSWBQQ1aIWRAu9GrBPRBqeAqJa1IJopY+D+jW1iDQ4BUS1IEEx0USL9XGgTwEhIo1NATFAOdVMK73s7yvUuxQRkbpSQAzg6Vaa1YIQEVFAHCXdSgt9HFALQkQanAJigCDbRit97O9VQIhIY1NADJDIttFivTrFJCINTwExQJBpo836OKDLXEWkwSkgBkq30Go6xSQiooAYKNNGM7qKSUREATFQupUm+tjfm693JSIidaWAGCgT3pc636chv0WksSkgBsqMA8B799W5EBGR+lJADNTUDkAit6fOhYiI1JcCYqDmiQCkcnvrXIiISH0pIAZqCgOipbSfvG4aJCINTAExUNSCaLeDGo9JRBqaAmKgqAUxgQPs128hRKSBKSAGSmUpJZrUghCRhqeAqKGYmRAFhFoQItK4FBA1eNNEJnCAPT36NbWINC4FRA1By0Ta7SDdBxUQItK4Yg0IM1tiZpvMbLOZLauxPGNm342WP25ms6P5s82s18yeiB5fi7POgZKtk2nnILsO5kbybUVERpVkXDs2swRwG/BmoBNYY2Yr3f3pqtU+COxx998xs+uALwBLo2XPufuCuOo7lqB5IhMDBYSINLY4WxCLgc3uvsXd88DdwNUD1rka+GY0vQK41MwsxpqGpnkibRxi1/6+elciIlI3cQbEDODFqted0bya67h7EdgHTIqWzTGzX5nZj83s4lpvYGY3mNlaM1vb1dU1fJU3TSRBmd4Du4dvnyIip5jR2kn9EvAqd18I/AXwHTMbN3Ald7/D3TvcvWPKlCnD9+7Rr6mLB3cN3z5FRE4xcQbENmBW1euZ0bya65hZEhgPdLt7zt27Adx9HfAc8JoYaz1S9Gtq79mNu4/Y24qIjCZxBsQa4Cwzm2NmaeA6YOWAdVYC74+mrwF+5O5uZlOiTm7M7NXAWcCWGGs9UnN4lqultI9D+dKIva2IyGgS21VM7l40s48CDwEJYLm7bzCzm4G17r4S+AbwbTPbDOwmDBGAS4CbzawAlIE/c/eR6xBomwrAVNtD14EcrZnY/kwiIqNWrN987r4KWDVg3meqpvuAa2tsdy9wb5y1HVPr6bglmG7d7DqYY87klrqVIiJSL6O1k7q+EkmKzVPDgDig30KISGNSQAzCx89kGt36sZyINCwFxCCS7TOZHnTTpRaEiDQoBcQggvEzmWa76dzTU+9SRETqQgExmPGzyFBgz66X6l2JiEhdKCAGMz4cFaS4+7d1LkREpD4UEIMZFwZEc+/LHMzpznIi0ngUEIMZH44SMs26eaH7UJ2LEREZeQqIwTRPpJRs5gzbwW+71VEtIo1HATEYM/z08zg3eJ6tCggRaUAKiGNIzlzE/GArnd376l2KiMiIU0Acy/SFZMnTt31jvSsRERlxCohjmb4QgNSO9fQVNOy3iDQWBcSxTDyTYrKFc3iOdS/sqXc1IiIjSgFxLEEAMzu4OPFrHt08jPe8FhE5BSggjiO54N3MsZfZ/8zqepciIjKiFBDHM+9t9CXHsbj7ATbvPFjvakRERowC4nhSTfhr380VwS/493+/r97ViIiMGAXEEDS9+dMcyJ7OtS98lic2/qbe5YiIjAgFxFBkx5N6178yyfbT/N1r2PJbjfAqImOfAmKIWs+8gL1X/StnsJ308ktZ+3N1WovI2KaAOAGnL3oLe6+9j6wVWfAf72D1rR9g63Ob6l2WiEgskvUu4FQzdd7F9M1aw8Y7P8HFL98P37qf/9d0MaVzl3Lu66+ifXxbvUsUERkW5u71rmFYdHR0+Nq1a0f0Pfdsf47nV/0Dr+n8Pq0cYr838WR6ET3TLmDCOX/AnHPO57RxzSNak4jIiTCzde7eUXOZAuKV80IfW9Y8SN/6+zmt61GmlHYC0O1tbArOZE/rWZSmzKNl1rlMnHU2s06fwqSWNGZWl3pFRCoUECMs1/U8nb/6T0pbH6V59wam9j1PisO3Le3ycWxjKnsy0+lpmYWPfxU2cQ7Z085kwtRZTJ3QymltWdJJdRGJSLwUEPVWKlDYuYnuLU9yaMdmit3Pk9r/W9p6tzGxuJME5f5Vy27spo0uH8+eoJ2DiXYOpSeTz06m1DyZRMskUm2TybRNpnnCVMZNmMik1gztLWnaMkmCQK0SERm6YwWEOqlHQiJFatp8Tp82/+hlpQK+r5ODL23m4MvPktuzjdL+l0kf6uJVvbtoKmyire/npHvzUGNA2YIn2EsLO7yNTbRxMGijJzmBXGo8+fQESk2ToKmdoHkiqdZJZFsnkGoeT7aljdZsmtZskpZ0ktZMkpZMUq0WEemngKi3RAqbOIe2iXNom/fm2uu4Q+4AHOrCe7rJHdjFoT07ye3vIn+gGz+0i1TPbk7P7SWT7yZb2EJz735SvQUY5GZ4ZTcOkeUgTRz0JnbRxAFvoseayCVayCeaKSRaKaVaIN0MqWYSqSYs04ylmwlSTQTpZhKZFpKZJpKZFhKZFtLZJrLpFJlkQDaViB4BmWSCdDIgnQhIJUz9LyKnAAXEqcAMsuMgOw6bdCZZIHu8bdwhfxB6dkPvbvxQN30Huuk7tI9Cz36Kvfso9+7HcwfI5g7SlD/A6YWDJAu7SBW3kin1kCn2EOTKx3uno+Q8SZ4UOVLkSZLzFPuj6Twp8qQokKIYpChamqKlKQUpSkGacpCmnMhQDtJ4ovLI4IkMJDJ4Mo0ls5BMEyQzWDKLpTIEySyWzpJMZUikMwSpLEEySyqZIJUISCYsfA7C51QiIJMMSCfD50wqQSphpIJAp+lEIgqIscoMMm3ho/0MDGiKHkPmDoUeKPRWPYePUu4QhVwPhb5DFHM9FHOHKOV6KOcPUS7k8EJf+FzMQTFHppQjW8phpTxBOU9QyhOUD5Eo5/sfyWKBpBdIeZ6AEw+mWvKeqAqrFPmq8DpUCSxPkiNNLnpdJEnJwkc5epQsSTlIUbYU5SCcJkhRtiSeSOFBEg9SWCKNBylIpCBIQjKNBSlIpggSaUiksWSKIJHCkmmCZJogkSJIpkklA5JBGGLJhJFMBKSC8DkZGInADj8njEQQkLDq11XLg4AgoH95EBiBGQmzI+arJSfHooCQwZlBuiV8DJCIHsdtyZysUhFKYbhQzEXTeSj2QSkPxTB8SoVeSvkcxXwfpUIv5UKOUiFHudCHF/rwYh5KYWBZKUemmCdTyjGumINSHquEVukAVs6TKOUJvEhQLoTPXiThRZLlAsOUWYPKe4IiSYokyEfPBU9SIEGRcFmBBGUCSgTkCCh7QAmjTECRBCWC/uWV5/7pqnWPWM8SuCVwAtwSlC3ALThiXv/rAc9lwulyZd0g6J8XLg/3RTRN1f7NAtwMLIEBZQvCwLIALMCw/uVgWBCub/3zCJ8Dwwi3cwswAgjC14FVzY+2DaJQ7MmHtxFuSiXIpBJYEGAGhkXP9L8OohfV88yit6kK2XLZKZSdUrlM2SEZBXMyCunK61q5XL0fO2I+g8wPXwUGU9qyLJl/+sn+pzeoWAPCzJYA/4vwu+R/u/stA5ZngG8B5wPdwFJ33xot+yTwQaAE3BFFWTcAAAdzSURBVOjuD8VZq4wyiWT4qBFOFUb4H3ASyMRdjzuUS2E4lQtRgFWmK49jLDtqvSLlYo5ysUC5mA8fpQJezGOlPOligVQpT7ZUDIOxfHg/Xi6HtXjpiGfzwuHXXsa8hEXP9E8fOT+oPBPO62+5efRoIGU3HMJQw3CMcvQc/jkOT1d/VXv/c/W8o5cPtk5lf7XepzJ9uL4j66rs56Wms2D+ymH5O1SLLSDMLAHcBrwZ6ATWmNlKd3+6arUPAnvc/XfM7DrgC8BSMzsHuA6YB0wHHjaz17h7Ka56RY7J7HBoDZOAUTgYmjt47QAadP6JrNs/vxw+8MPTlfeGqnnV84+3rh9jv354HgP/+R4uD6L1E4O+j+PRvr2yGY6796dAYNFXfeWf/R6u6+6UPVzXK3/nqvd2jyKhv9ZwmXu5f75XH0d/jeH8GRNfPXz/DVSJswWxGNjs7lsAzOxu4GqgOiCuBj4bTa8A/snCv+zVwN3ungOeN7PN0f5+HmO9IlI5fRMk6l3JqGQDnoe6jTEK/zEwBHHWPAN4sep1ZzSv5jruXiS8KHPSELfFzG4ws7Vmtrarq2sYSxcRkVMx1Pq5+x3u3uHuHVOmTKl3OSIiY0qcAbENmFX1emY0r+Y6ZpYExhN2Vg9lWxERiVGcAbEGOMvM5phZmrDTeWA3+0rg/dH0NcCPPBwcaiVwnZllzGwOcBbwixhrFRGRAWLrpHb3opl9FHiI8DLX5e6+wcxuBta6+0rgG8C3o07o3YQhQrTePYQd2kXgI7qCSURkZGk0VxGRBnas0VxP6U5qERGJjwJCRERqGjOnmMysC3jhFexiMrBrmMo5VeiYG4OOuTGc7DGf4e41fycwZgLilTKztYOdhxurdMyNQcfcGOI4Zp1iEhGRmhQQIiJSkwLisDvqXUAd6Jgbg465MQz7MasPQkREalILQkREalJAiIhITQ0fEGa2xMw2mdlmM1tW73riYmZbzezXZvaEma2N5k00sx+Y2bPRc3u963ylzGy5me00s6eq5tU8Tgt9Jfrs15vZovpVfvIGOebPmtm26PN+wsyurFr2yeiYN5nZH9an6pNnZrPMbLWZPW1mG8zsY9H8sf45D3bc8X3WXrkNXgM+CAcRfA54NZAGngTOqXddMR3rVmDygHl/DyyLppcBX6h3ncNwnJcAi4CnjnecwJXAg4Q3/LoQeLze9Q/jMX8W+Msa654T/XeeAeZE//0n6n0MJ3i804BF0XQb8JvouMb65zzYccf2WTd6C6L/tqjungcqt0VtFFcD34ymvwm8rY61DAt3/wnhyMDVBjvOq4FveegxYIKZTRuZSofPIMc8mP7b+br780Dldr6nDHd/yd1/GU0fADYS3nFyrH/Ogx33YF7xZ93oATGkW5uOEQ78p5mtM7MbonlT3f2laPplYGp9SovdYMc51j//j0anVJZXnT4cU8dsZrOBhcDjNNDnPOC4IabPutEDopG83t0XAVcAHzGzS6oXetgmHfPXPDfKcQJfBc4EFgAvAf+zvuUMPzNrBe4FPu7u+6uXjeXPucZxx/ZZN3pANMytTd19W/S8E7iPsKm5o9LUjp531q/CWA12nGP283f3He5ecvcy8HUOn1oYE8dsZinCL8k73f370ewx/znXOu44P+tGD4ih3Bb1lGdmLWbWVpkGLgee4shbvr4feKA+FcZusONcCfyX6CqXC4F9VacoTmkDzrG/nfDzhjFwO18zM8K7UW509y9XLRrTn/Ngxx3rZ13vnvl6PwivcPgNYQ//p+tdT0zH+GrCqxmeBDZUjhOYBPwQeBZ4GJhY71qH4VjvImxmFwjPuX5wsOMkvKrltuiz/zXQUe/6h/GYvx0d0/roi2Ja1fqfjo55E3BFves/ieN9PeHpo/XAE9Hjygb4nAc77tg+aw21ISIiNTX6KSYRERmEAkJERGpSQIiISE0KCBERqUkBISIiNSkgREYBM3ujmf17vesQqaaAEBGRmhQQIifAzN5rZr+Ixt2/3cwSZnbQzP4hGqP/h2Y2JVp3gZk9Fg2idl/V/Ql+x8weNrMnzeyXZnZmtPtWM1thZs+Y2Z3RL2dF6kYBITJEZjYXWApc5O4LgBLwHqAFWOvu84AfAzdFm3wL+G/ufh7hL10r8+8EbnP31wK/T/graAhH5/w44Tj+rwYuiv2gRI4hWe8CRE4hlwLnA2uif9w3EQ4IVwa+G63zf4Dvm9l4YIK7/zia/03ge9GYWDPc/T4Ad+8DiPb3C3fvjF4/AcwGfhb/YYnUpoAQGToDvununzxiptnfDFjvZMevyVVNl9D/n1JnOsUkMnQ/BK4xs9Og/x7IZxD+f3RNtM4fAz9z933AHjO7OJr/PuDHHt4JrNPM3hbtI2NmzSN6FCJDpH+hiAyRuz9tZn9NeGe+gHD01I8Ah4DF0bKdhP0UEA45/bUoALYAH4jmvw+43cxujvZx7QgehsiQaTRXkVfIzA66e2u96xAZbjrFJCIiNakFISIiNakFISIiNSkgRESkJgWEiIjUpIAQEZGaFBAiIlLT/wczs0XX8oso6gAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpPQBAxvRZGG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b731f6ea-f0bc-420d-f867-1b87b44f3d94"
      },
      "source": [
        "#a=model.predict(df_01_05_15_results_inputs_scaled1)\r\n",
        "#scaler_y.inverse_transform(a)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 92.68931 ,  75.20591 , 562.8004  , 192.12563 ],\n",
              "       [ 79.21683 ,  70.09466 , 614.07263 , 180.41298 ],\n",
              "       [ 97.3393  ,  76.18681 , 644.54694 , 193.49977 ],\n",
              "       [ 72.662476,  79.57008 , 814.09125 , 154.11565 ],\n",
              "       [ 94.261894,  71.04864 , 506.5745  , 195.1996  ],\n",
              "       [ 93.24195 ,  83.22248 , 702.7843  , 188.23328 ],\n",
              "       [ 87.01631 ,  79.02677 , 614.42596 , 166.9139  ],\n",
              "       [ 87.42415 ,  77.06194 , 558.68445 , 192.44473 ],\n",
              "       [ 90.990715,  74.8249  , 550.2379  , 189.71843 ],\n",
              "       [ 89.75087 ,  74.27133 , 542.053   , 187.76175 ],\n",
              "       [ 92.553795,  75.178345, 557.3812  , 192.34453 ],\n",
              "       [ 79.59551 ,  69.79492 , 612.1514  , 181.21576 ],\n",
              "       [ 97.15341 ,  76.36309 , 646.17993 , 193.14886 ],\n",
              "       [ 73.92688 ,  78.46273 , 804.713   , 156.38695 ],\n",
              "       [ 93.69009 ,  71.42945 , 511.9131  , 194.12383 ],\n",
              "       [ 93.829605,  83.15869 , 705.6896  , 189.2457  ],\n",
              "       [ 87.56672 ,  79.22599 , 618.425   , 168.20529 ],\n",
              "       [ 88.13339 ,  76.58597 , 562.5323  , 193.28902 ],\n",
              "       [ 90.02189 ,  75.60354 , 549.80676 , 188.20235 ],\n",
              "       [ 90.11642 ,  74.212234, 551.1701  , 187.62444 ],\n",
              "       [ 93.06467 ,  74.806984, 559.28735 , 193.00325 ],\n",
              "       [ 79.76027 ,  69.637924, 611.141   , 181.56538 ],\n",
              "       [ 96.65857 ,  76.38408 , 645.0615  , 192.07242 ],\n",
              "       [ 73.3418  ,  79.65192 , 816.48206 , 155.17163 ],\n",
              "       [ 93.58656 ,  71.44878 , 509.92816 , 194.13779 ],\n",
              "       [ 93.565926,  82.88574 , 699.247   , 188.85265 ],\n",
              "       [ 85.75893 ,  79.94811 , 622.2009  , 164.48611 ],\n",
              "       [ 87.10237 ,  77.18181 , 549.56683 , 192.31184 ],\n",
              "       [ 90.58409 ,  75.24173 , 553.6362  , 188.80981 ],\n",
              "       [ 90.92435 ,  73.31078 , 542.0954  , 189.63757 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blofpALXCq2q"
      },
      "source": [
        "#prediction for 1, 5, and 15 percent deviated inputs from backward model\r\n",
        "ynew1= model.predict(X_test1)\r\n",
        "#below is to predict for 1, 5, and 15% deviation inputs\r\n",
        "#ynew1_1_05_15= model.predict(df_01_05_15_results_inputs_scaled1)\r\n",
        "#ynew1_1_05_15\r\n",
        "#ynew1_05_15=scaler_y.inverse_transform(ynew1_1_05_15)\r\n",
        "#ynew1_05_15\r\n",
        "#df_ predicted_output_01_05_15= pd.DataFrame(data=ynew1_05_15)\r\n",
        "#df1515_predicted = pd.DataFrame(data=ynew1_05_15, columns=[\"Ft\",\"Fn\",\"P\", \"T\"])\r\n",
        "#from google.colab import files\r\n",
        "#df22225454.to_excel('df_01_05_15_forward_predicted.xlsx')\r\n",
        "#files.download('df_01_05_15_forward_predicted.xlsx')\r\n",
        "#df22225454.iloc[9:25, 1:2]\r\n",
        "#referense\r\n",
        "#df1515_predicted.iloc[10:20, 0:1]\r\n",
        "#df_01_05_15_results_outputs\r\n",
        "\r\n",
        "\r\n",
        "#prediction for 20 percent deviation\r\n",
        "#ynew1_20= model.predict(df_20_results_inputs_scaled)\r\n",
        "#ynew20=scaler_y.inverse_transform(ynew1_20)\r\n",
        "#ynew20\r\n",
        "#df_20_predicted=pd.DataFrame(data=ynew20, columns=['Ft','Fn','P','T'])\r\n",
        "#df_20_predicted\r\n",
        "#from google.colab import files\r\n",
        "#df_20_predicted.to_excel('df_20_predicted.xlsx')\r\n",
        "#files.download('df_20_predicted.xlsx')\r\n",
        "\r\n",
        "\r\n",
        "##prediction for 10 25 percent deviation\r\n",
        "#ynew1_10_25= model.predict(df_10_25_results_inputs_scaled)\r\n",
        "#ynew10_25=scaler_y.inverse_transform(ynew1_10_25)\r\n",
        "#ynew10_25\r\n",
        "#df_10_25_predicted=pd.DataFrame(data=ynew10_25, columns=['Ft','Fn','P','T'])\r\n",
        "#df_10_25_predicted\r\n",
        "#from google.colab import files\r\n",
        "#df_10_25_predicted.to_excel('df_10_25_predicted.xlsx')\r\n",
        "#files.download('df_10_25_predicted.xlsx')\r\n",
        "\r\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-s72BbCSdTm1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-1T1q_dZ4nk",
        "outputId": "cc2cc306-d1f1-4617-d952-187fb7628ce1"
      },
      "source": [
        "# to download the df_20_results dataset and compute mape with df_20_predicted dataset\r\n",
        "df_20_results = pd.read_excel('/content/gdrive/My Drive/PhD with Dr Anahita/projects/chatter/df_20_results.xlsx')\r\n",
        "df_20_results.columns=['A','B','c','n','m','h','Ft','Fn','P','T']\r\n",
        "df_20_results_only_outputs=df_20_results[['Ft','Fn','P','T']]\r\n",
        "np.mean(abs(df_20_results_only_outputs.iloc[0:10, 3:4].to_numpy()-df_20_predicted.iloc[0:10, 3:4].to_numpy())/df_20_results_only_outputs.iloc[0:10, 3:4].to_numpy()*100)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.4991371038386219"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 979
        },
        "id": "f3fwOce4kZDD",
        "outputId": "5b164245-aa42-47e5-d188-0793fb3daf8d"
      },
      "source": [
        "df444 = pd.read_excel('/content/gdrive/My Drive/PhD with Dr Anahita/projects/chatter/df4.xlsx')\r\n",
        "df444.columns = ['t','FEA','FEA','FEA','FEA','FEA','FEA','FEA','FEA','FEA','FEA','ten','ten','ten','ten','ten','ten','ten','ten','ten','ten','tfive','tfive','tfive','tfive','tfive','tfive','tfive','tfive','tfive','tfive']\r\n",
        "df4445=df444.T\r\n",
        "df4445.columns=['Ft','Fn','P','T']\r\n",
        "df4445\r\n",
        "#df4445.iloc[0:1, 0:1]\r\n",
        "#df4445.drop[0:1, axis=0]\r\n",
        "df4445=df4445.drop(['t'])\r\n",
        "df4445.iloc[0:10, 0:1].to_numpy()\r\n",
        "df4445\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Ft</th>\n",
              "      <th>Fn</th>\n",
              "      <th>P</th>\n",
              "      <th>T</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>FEA</th>\n",
              "      <td>125.433</td>\n",
              "      <td>83.982</td>\n",
              "      <td>1003.47</td>\n",
              "      <td>322.145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FEA</th>\n",
              "      <td>97.9602</td>\n",
              "      <td>73.3427</td>\n",
              "      <td>783.682</td>\n",
              "      <td>273.915</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FEA</th>\n",
              "      <td>125.818</td>\n",
              "      <td>78.4145</td>\n",
              "      <td>1006.54</td>\n",
              "      <td>314.992</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FEA</th>\n",
              "      <td>119.009</td>\n",
              "      <td>93.6906</td>\n",
              "      <td>952.069</td>\n",
              "      <td>327.104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FEA</th>\n",
              "      <td>106.134</td>\n",
              "      <td>72.8844</td>\n",
              "      <td>849.071</td>\n",
              "      <td>281.632</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FEA</th>\n",
              "      <td>119.261</td>\n",
              "      <td>73.2355</td>\n",
              "      <td>954.088</td>\n",
              "      <td>299.698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FEA</th>\n",
              "      <td>131.48</td>\n",
              "      <td>81.9317</td>\n",
              "      <td>1051.84</td>\n",
              "      <td>330.808</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FEA</th>\n",
              "      <td>117.85</td>\n",
              "      <td>83.5403</td>\n",
              "      <td>942.802</td>\n",
              "      <td>318.705</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FEA</th>\n",
              "      <td>125.914</td>\n",
              "      <td>84.1501</td>\n",
              "      <td>1007.31</td>\n",
              "      <td>330.258</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FEA</th>\n",
              "      <td>128.261</td>\n",
              "      <td>88.2943</td>\n",
              "      <td>1026.09</td>\n",
              "      <td>339.054</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ten</th>\n",
              "      <td>125.269</td>\n",
              "      <td>82.59</td>\n",
              "      <td>1002.15</td>\n",
              "      <td>320.672</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ten</th>\n",
              "      <td>97.8512</td>\n",
              "      <td>73.7202</td>\n",
              "      <td>782.81</td>\n",
              "      <td>270.943</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ten</th>\n",
              "      <td>125.823</td>\n",
              "      <td>78.2762</td>\n",
              "      <td>1006.59</td>\n",
              "      <td>313.401</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ten</th>\n",
              "      <td>119.843</td>\n",
              "      <td>93.5775</td>\n",
              "      <td>958.744</td>\n",
              "      <td>326.738</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ten</th>\n",
              "      <td>105.357</td>\n",
              "      <td>72.1517</td>\n",
              "      <td>842.855</td>\n",
              "      <td>281.548</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ten</th>\n",
              "      <td>118.936</td>\n",
              "      <td>74.1259</td>\n",
              "      <td>951.484</td>\n",
              "      <td>297.307</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ten</th>\n",
              "      <td>131.186</td>\n",
              "      <td>82.1798</td>\n",
              "      <td>1049.49</td>\n",
              "      <td>325.867</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ten</th>\n",
              "      <td>118.501</td>\n",
              "      <td>86.4536</td>\n",
              "      <td>948.005</td>\n",
              "      <td>317.877</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ten</th>\n",
              "      <td>126.588</td>\n",
              "      <td>87.0558</td>\n",
              "      <td>1012.71</td>\n",
              "      <td>330.908</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ten</th>\n",
              "      <td>129.259</td>\n",
              "      <td>87.256</td>\n",
              "      <td>1034.07</td>\n",
              "      <td>341.49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tfive</th>\n",
              "      <td>123.437</td>\n",
              "      <td>81.3014</td>\n",
              "      <td>987.492</td>\n",
              "      <td>321.542</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tfive</th>\n",
              "      <td>98.8932</td>\n",
              "      <td>74.5533</td>\n",
              "      <td>791.146</td>\n",
              "      <td>272.049</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tfive</th>\n",
              "      <td>125.535</td>\n",
              "      <td>79.3377</td>\n",
              "      <td>1004.28</td>\n",
              "      <td>309.963</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tfive</th>\n",
              "      <td>121.828</td>\n",
              "      <td>93.4664</td>\n",
              "      <td>974.624</td>\n",
              "      <td>329.111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tfive</th>\n",
              "      <td>107.475</td>\n",
              "      <td>73.5819</td>\n",
              "      <td>859.799</td>\n",
              "      <td>283.798</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tfive</th>\n",
              "      <td>119.397</td>\n",
              "      <td>73.956</td>\n",
              "      <td>955.178</td>\n",
              "      <td>296.193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tfive</th>\n",
              "      <td>130.457</td>\n",
              "      <td>81.4558</td>\n",
              "      <td>1043.66</td>\n",
              "      <td>333.283</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tfive</th>\n",
              "      <td>115.851</td>\n",
              "      <td>86.7548</td>\n",
              "      <td>926.809</td>\n",
              "      <td>313.724</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tfive</th>\n",
              "      <td>126.235</td>\n",
              "      <td>86.0498</td>\n",
              "      <td>1009.88</td>\n",
              "      <td>333.653</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tfive</th>\n",
              "      <td>126.89</td>\n",
              "      <td>88.4382</td>\n",
              "      <td>1015.12</td>\n",
              "      <td>333.112</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Ft       Fn        P        T\n",
              "FEA    125.433   83.982  1003.47  322.145\n",
              "FEA    97.9602  73.3427  783.682  273.915\n",
              "FEA    125.818  78.4145  1006.54  314.992\n",
              "FEA    119.009  93.6906  952.069  327.104\n",
              "FEA    106.134  72.8844  849.071  281.632\n",
              "FEA    119.261  73.2355  954.088  299.698\n",
              "FEA     131.48  81.9317  1051.84  330.808\n",
              "FEA     117.85  83.5403  942.802  318.705\n",
              "FEA    125.914  84.1501  1007.31  330.258\n",
              "FEA    128.261  88.2943  1026.09  339.054\n",
              "ten    125.269    82.59  1002.15  320.672\n",
              "ten    97.8512  73.7202   782.81  270.943\n",
              "ten    125.823  78.2762  1006.59  313.401\n",
              "ten    119.843  93.5775  958.744  326.738\n",
              "ten    105.357  72.1517  842.855  281.548\n",
              "ten    118.936  74.1259  951.484  297.307\n",
              "ten    131.186  82.1798  1049.49  325.867\n",
              "ten    118.501  86.4536  948.005  317.877\n",
              "ten    126.588  87.0558  1012.71  330.908\n",
              "ten    129.259   87.256  1034.07   341.49\n",
              "tfive  123.437  81.3014  987.492  321.542\n",
              "tfive  98.8932  74.5533  791.146  272.049\n",
              "tfive  125.535  79.3377  1004.28  309.963\n",
              "tfive  121.828  93.4664  974.624  329.111\n",
              "tfive  107.475  73.5819  859.799  283.798\n",
              "tfive  119.397   73.956  955.178  296.193\n",
              "tfive  130.457  81.4558  1043.66  333.283\n",
              "tfive  115.851  86.7548  926.809  313.724\n",
              "tfive  126.235  86.0498  1009.88  333.653\n",
              "tfive   126.89  88.4382  1015.12  333.112"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wsJ6vD3kZHn",
        "outputId": "375ef162-ca93-4c49-ed89-b6631b2f6cb1"
      },
      "source": [
        "np.mean(abs(df4445.iloc[0:10, 3:4].to_numpy()-df4445.iloc[20:30, 3:4].to_numpy())/df4445.iloc[0:10, 3:4].to_numpy()*100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0108693021801793"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6xBDMuhr1F0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVpWgJHnkZKd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0u8eqelxCrNm"
      },
      "source": [
        "ynew = scaler_y.inverse_transform(ynew1) \n",
        "y_test=scaler_y.inverse_transform(y_test1) \n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_i9SMFQXCrhu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fgwtM-zRoXY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0af0ecbf-fe96-4bad-f554-f507c10562ed"
      },
      "source": [
        "mse_FT=np.mean((y_test[:,0].reshape(300,1)- ynew[:,0].reshape(300,1))**2)\n",
        "r_value_FT=r2_score(y_test[:,0].reshape(300,1), ynew[:,0].reshape(300,1))\n",
        "Rmse_FT=sqrt(mean_squared_error(y_test[:,0].reshape(300,1), ynew[:,0].reshape(300,1)))\n",
        "print(\"mse_FT:\",mse_FT )\n",
        "print(\"r_squared_FT:\",r_value_FT )\n",
        "#np.mean(abs(y_test[:,0].reshape(300,1)-ynew[:,0].reshape(300,1))/df4445.iloc[0:10, 3:4].to_numpy()*100)\n",
        "print('Ft Mape:', np.std(abs((y_test[:,0].reshape(300,1)-ynew[:,0].reshape(300,1))/y_test[:,0].reshape(300,1))*100))\n",
        "print('Fn Mape:', np.std(abs((y_test[:,1].reshape(300,1)-ynew[:,1].reshape(300,1))/y_test[:,1].reshape(300,1))*100))\n",
        "print('P Mape:', np.std(abs((y_test[:,2].reshape(300,1)-ynew[:,2].reshape(300,1))/y_test[:,2].reshape(300,1))*100))\n",
        "print('T Mape:', np.std(abs((y_test[:,3].reshape(300,1)-ynew[:,3].reshape(300,1))/y_test[:,3].reshape(300,1))*100))\n",
        "print('Ft CI', )\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mse_FT: 12.916776594630734\n",
            "r_squared_FT: 0.928113326811829\n",
            "Ft Mape: 1.9354956437183761\n",
            "Fn Mape: 3.0307814932748847\n",
            "P Mape: 1.9978905611443045\n",
            "T Mape: 2.744648301935659\n",
            "Ft CI\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "id": "gPYIl0REAzgc",
        "outputId": "4163e444-0b67-4d7b-bfbc-57ff419b8689"
      },
      "source": [
        "a = range(10,14)\r\n",
        "mean_confidence_interval(a)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-1b285258e32b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmean_confidence_interval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'mean_confidence_interval' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2nTaP3G7POE"
      },
      "source": [
        "# to calculate the MAPE of forward model multivariate vs univariate\r\n",
        "#Ft Mape: 1.8258244346945924\r\n",
        "#Fn Mape: 2.3235874400894945\r\n",
        "#P Mape: 1.8923191315443009\r\n",
        "#T Mape: 2.3041402135459066\r\n",
        "#std \r\n",
        "#Ft : 2.0776245367199793\r\n",
        "#Fn : 3.034701223900676\r\n",
        "#P : 2.159217714377859\r\n",
        "#T  2.84170767742113\r\n",
        "#univariate\r\n",
        "#Ft Mape: 1.9780514862965781\r\n",
        "#Fn Mape: 2.108305489102834\r\n",
        "#P 2.03593219654611\r\n",
        "#2.5171358324890565\r\n",
        "#std\r\n",
        "#ft 2.096629050535722\r\n",
        "#Fn  3.5734427581234978\r\n",
        "# P 2.8380448895572687\r\n",
        "#T 3.3153570611841987\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODGbE9DDtV9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ba809f8-76cd-41d7-899a-8e97bee13f76"
      },
      "source": [
        "# to calculate MSE\n",
        "#mse_FN=np.mean((y_test[:,1].reshape(300,1)- ynew[:,1].reshape(300,1))**2)\n",
        "#to calculate RMSE\n",
        "Rmse_FN=sqrt(mean_squared_error(y_test[:,1].reshape(300,1), ynew[:,1].reshape(300,1)))\n",
        "r_value_FN=r2_score(y_test[:,1].reshape(300,1), ynew[:,1].reshape(300,1))\n",
        "print(\"Rmse_FN:\",Rmse_FN )\n",
        "print(\"r_squared_FT:\",r_value_FN )\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Rmse_FN: 3.1529060430015634\n",
            "r_squared_FT: 0.875696306886373\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGtaRc9srzaa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f484dd4-6863-4738-dcaf-21af7d77d50e"
      },
      "source": [
        "Rmse_P=sqrt(mean_squared_error(y_test[:,2].reshape(300,1), ynew[:,2].reshape(300,1)))\n",
        "r_value_P=r2_score(y_test[:,2].reshape(300,1), ynew[:,2].reshape(300,1))\n",
        "print(\"mse_FT:\",Rmse_P )\n",
        "print(\"r_squared_FT:\",r_value_P )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mse_FT: 29.99297220492891\n",
            "r_squared_FT: 0.9217732796015162\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3ZQy1kl3lMH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1658a215-3cd8-4bba-f55a-1cb052099052"
      },
      "source": [
        "Rmse_T=sqrt(mean_squared_error(y_test[:,3].reshape(300,1), ynew[:,3].reshape(300,1)))\n",
        "r_value_T=r2_score(y_test[:,3].reshape(300,1), ynew[:,3].reshape(300,1))\n",
        "print(\"Rmse_T:\",Rmse_T )\n",
        "print(\"r_squared_FT:\",r_value_T )\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Rmse_T: 11.038377723580421\n",
            "r_squared_FT: 0.8102570311112924\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PoesXuRfk9bc"
      },
      "source": [
        "#X_train2, X_test2, y_train2, y_test2 = train_test_split(yscale1,xscale1, test_size=.3, random_state=45)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KshXgzEk9uy"
      },
      "source": [
        "comm='''\n",
        "model1 = Sequential()\n",
        "model1.add(Dense(10, input_dim=4, kernel_initializer=keras.initializers.glorot_uniform(seed=66), activation='relu'))\n",
        "model1.add(Dense(20,kernel_initializer=keras.initializers.glorot_uniform(seed=66), activation='relu'))\n",
        "model1.add(Dense(6,kernel_initializer=keras.initializers.glorot_uniform(seed=66), activation='linear'))\n",
        "model1.summary()\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0WCljo4akKw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2E48hOV4WtW"
      },
      "source": [
        "#model1.compile(loss='mse', optimizer='adam', metrics=['mse','mae'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghGl_P3Zk-Aa"
      },
      "source": [
        "#>>> history = model1.fit(y_train1, X_train1 ,epochs=250, batch_size=50, verbose=1,validation_split=0.3, callbacks=EarlyStopping(monitor='val_loss', verbose=1,patience=15))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3LyzXA7k-W6"
      },
      "source": [
        "#ynew2= model1.predict(y_test1)\n",
        "#ynew2.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jW6YCvRHnGrJ"
      },
      "source": [
        "#ynew11 = scaler_x.inverse_transform(ynew2) \n",
        "#y_test11=scaler_x.inverse_transform(y_test2) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-D5K_Pbk-uS"
      },
      "source": [
        "comm=''' \n",
        "mse_A=np.mean((y_test11[:,0].reshape(300,1)- ynew11[:,0].reshape(300,1))**2)\n",
        "r_value_A=r2_score(y_test11[:,0].reshape(300,1), ynew11[:,0].reshape(300,1))\n",
        "print(\"mse_FT:\",mse_A )\n",
        "print(\"r_squared_FT:\",r_value_A )\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsgXl7SInZ1d"
      },
      "source": [
        "#r2_score(y_test11[:,1].reshape(300,1), ynew11[:,1].reshape(300,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6B0tXNynkVU"
      },
      "source": [
        "#r2_score(y_test11[:,2].reshape(300,1), ynew11[:,2].reshape(300,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0kXtEupnufU"
      },
      "source": [
        "#r2_score(y_test11[:,3].reshape(300,1), ynew11[:,3].reshape(300,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsgKWdSF78mP"
      },
      "source": [
        "#r2_score(y_test11[:,4].reshape(300,1), ynew11[:,4].reshape(300,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f461GeLP7_T7"
      },
      "source": [
        "#r2_score(y_test11[:,5].reshape(300,1), ynew11[:,5].reshape(300,1))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}